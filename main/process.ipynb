{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import sys\n",
    "import os \n",
    "from pathlib import Path \n",
    "from dataset import Translate_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "from einops import repeat\n",
    "from neural_net import EncoderRNN, Attn, LuongAttnDecoderRNN\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   input  \\\n",
      "0             gosh if only we could find kat a boyfriend   \n",
      "1                           cesc ma tete this is my head   \n",
      "2                                                  there   \n",
      "3                       you have my word  as a gentleman   \n",
      "4                                                     hi   \n",
      "...                                                  ...   \n",
      "64661                         what oclock is it mr noggs   \n",
      "64662     are you dictating the strategy of this war sir   \n",
      "64663                                             stuart   \n",
      "64664  well fed or hungry pulleine wants them in posi...   \n",
      "64665   do you think she might be interested in  someone   \n",
      "\n",
      "                                         target  \n",
      "0                      let me see what i can do  \n",
      "1          right  see  youre ready for the quiz  \n",
      "2                                         where  \n",
      "3                                   youre sweet  \n",
      "4      looks like things worked out tonight huh  \n",
      "...                                         ...  \n",
      "64661                  eleven oclock my lorj 42  \n",
      "64662                  im explaining my reasons  \n",
      "64663                                       yes  \n",
      "64664            right  bombardier to me please  \n",
      "64665                                 which one  \n",
      "\n",
      "[64666 rows x 2 columns]\n",
      "VOCAB None\n",
      "NUMWORDS 26943\n"
     ]
    }
   ],
   "source": [
    "class Vocab:\n",
    "    def __init__(self, name=None):\n",
    "        self.name = name\n",
    "        self.word2idx = {\"PAD\": 0, \"SOS\": 1, \"EOS\": 2}\n",
    "        self.idx2word = {1: \"SOS\", 0: \"PAD\", 2: \"EOS\"} #3 special keywords\n",
    "        self.num_words = 3\n",
    "        self.word_counts = {} #SOS, EOS, PAD\n",
    "\n",
    "    def add_sentence(self, sentence):\n",
    "        for word in sentence.split():\n",
    "            self.add_word(word)\n",
    "    def add_word(self, word):\n",
    "        if word in self.word2idx.keys():\n",
    "            self.word_counts[word] += 1\n",
    "        else:\n",
    "            self.word2idx[word] = self.num_words\n",
    "            self.idx2word[self.num_words] = word\n",
    "            self.word_counts[word] = 1 \n",
    "            self.num_words += 1\n",
    "\n",
    "class normalize_funcs:\n",
    "    def __init__(self, rareword=None):\n",
    "        self.punctuation = string.punctuation\n",
    "        self.rareword = rareword\n",
    "    def lower_case(self, text):\n",
    "        return text.lower()\n",
    "\n",
    "    def remove_punctuation(self, text):\n",
    "        return text.translate(str.maketrans('', '', self.punctuation))\n",
    "\n",
    "    def remove_rareword(self, text):\n",
    "        return ' '.join(word for word in text.split() if word not in self.rareword)\n",
    "    def trimming(self, input, target, min_freq=3):\n",
    "        counter = {}\n",
    "        for arg in [input, target]:\n",
    "            for line in arg:\n",
    "                for word in line.split():\n",
    "                    if word in counter:\n",
    "                        counter[word] += 1\n",
    "                    else:\n",
    "                        counter[word] = 1\n",
    "\n",
    "        #min freq = 3\n",
    "\n",
    "        rare_words = []\n",
    "        for key, value in counter.items():\n",
    "            if value < min_freq:\n",
    "                rare_words.append(key)\n",
    "        #trimming\n",
    "        new_input = []\n",
    "        new_target = []\n",
    "        for line1, line2 in zip(input, target):\n",
    "            if word in line1 or word in line2:\n",
    "                continue\n",
    "            else:\n",
    "                new_input.append(line1)\n",
    "                new_target.append(line2)\n",
    "        return new_input, new_target\n",
    "\n",
    "vocab = Vocab()\n",
    "data = pd.read_csv(os.path.join('/home/xps/educate/code/NLP/chat_bot/data/cornell movie-dialogs corpus/pair_df.csv'), sep='@')\n",
    "print(data)\n",
    "for i in range(len(data)):\n",
    "    input, target = data.iloc[i, :]\n",
    "    for line in [input, target]:\n",
    "        vocab.add_sentence(line)\n",
    "print('VOCAB', vocab.name)\n",
    "print('NUMWORDS', vocab.num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           input  \\\n",
      "0     gosh if only we could find kat a boyfriend   \n",
      "1                   cesc ma tete this is my head   \n",
      "2                                          there   \n",
      "3               you have my word  as a gentleman   \n",
      "4                                             hi   \n",
      "...                                          ...   \n",
      "2995           in every sense if at all possible   \n",
      "2996                         wheres the restroom   \n",
      "2997              im going to be sick wheres the   \n",
      "2998                                        what   \n",
      "2999                          give me some money   \n",
      "\n",
      "                                          target  \n",
      "0                       let me see what i can do  \n",
      "1           right  see  youre ready for the quiz  \n",
      "2                                          where  \n",
      "3                                    youre sweet  \n",
      "4       looks like things worked out tonight huh  \n",
      "...                                          ...  \n",
      "2995  you cant hurt me more than im hurt already  \n",
      "2996                                        what  \n",
      "2997                           what no youre not  \n",
      "2998          shut up have you got your passport  \n",
      "2999                       i dont have any money  \n",
      "\n",
      "[3000 rows x 2 columns]\n",
      "---SHAPE torch.Size([11])\n",
      "---encoder input torch.Size([32, 11]) torch.Size([32, 11]) tensor([11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
      "        11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11])\n",
      "torch.Size([11, 32, 500]) torch.Size([4, 32, 500])\n",
      "--decode input torch.Size([1, 32])\n",
      "----decoder ouput torch.Size([32, 4039]) torch.Size([2, 32, 500])\n"
     ]
    }
   ],
   "source": [
    "    vocab = Vocab()\n",
    "    data = pd.read_csv(os.path.join('/home/xps/educate/code/NLP/chat_bot/data/cornell movie-dialogs corpus/pair_df.csv'), sep='@')\n",
    "    data = data.iloc[:3000]\n",
    "    print(data)\n",
    "    for i in range(len(data)):\n",
    "        input, target = data.iloc[i, :]\n",
    "        vocab.add_sentence(input)\n",
    "        vocab.add_sentence(target)\n",
    "    dataset = Translate_dataset(vocab, data)\n",
    "    print('---SHAPE', dataset[0][0].shape)\n",
    "    #loader \n",
    "    dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "    sample_input, sample_target, lengths, mask = iter(dataloader).next()\n",
    "    lengths, _ = lengths.sort(descending=True)\n",
    "    print('---encoder input', sample_input.shape, sample_target.shape, lengths)\n",
    "    #try the model \n",
    "    # Configure models\n",
    "    attn_model = 'dot'\n",
    "    #attn_model = 'general'\n",
    "    #attn_model = 'concat'\n",
    "    hidden_size = 500\n",
    "    encoder_n_layers = 2\n",
    "    decoder_n_layers = 2\n",
    "    dropout = 0.1\n",
    "    batch_size = 32 \n",
    "    embedding = nn.Embedding(vocab.num_words, hidden_size)\n",
    "    #define the model\n",
    "    encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n",
    "    decoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, vocab.num_words, decoder_n_layers, dropout)\n",
    "    #encode\n",
    "    encoder_output, encoder_hidden  = encoder(sample_input.reshape(11, 32), lengths)\n",
    "    print(encoder_output.shape, encoder_hidden.shape)\n",
    "    #decoder\n",
    "    decoder_input = torch.tensor([[vocab.word2idx['SOS'] for i in range(32)]])\n",
    "    print('--decode input', decoder_input.shape)\n",
    "    encoder_hidden = repeat(encoder_hidden[-1], 'b h -> n b h', n=decoder_n_layers)\n",
    "    decoder_output, decoder_hidden = decoder(decoder_input, encoder_hidden, encoder_output)\n",
    "    print('----decoder ouput', decoder_output.shape, decoder_hidden.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maskNLLLoss(inp, target, mask):\n",
    "    nTotal = mask.sum()\n",
    "    crossEntropy = -torch.log(torch.gather(inp, 1, target))\n",
    "    loss = crossEntropy.masked_select(mask).mean()\n",
    "    loss = loss.to('cpu')\n",
    "    return loss, nTotal.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 11])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(8.2910, grad_fn=<MeanBackward0>), 182)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maskNLLLoss(decoder_output, sample_target, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Size does not match at dimension 0 expected index [352, 1] to be smaller than self [32, 4039] apart from dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/xps/educate/code/NLP/chat_bot/main/process.ipynb Cell 7'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/xps/educate/code/NLP/chat_bot/main/process.ipynb#ch0000028vscode-remote?line=0'>1</a>\u001b[0m \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m decoder_output\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/xps/educate/code/NLP/chat_bot/main/process.ipynb#ch0000028vscode-remote?line=1'>2</a>\u001b[0m target \u001b[39m=\u001b[39m sample_target\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/xps/educate/code/NLP/chat_bot/main/process.ipynb#ch0000028vscode-remote?line=2'>3</a>\u001b[0m torch\u001b[39m.\u001b[39mlog(torch\u001b[39m.\u001b[39;49mgather(\u001b[39minput\u001b[39;49m, \u001b[39m1\u001b[39;49m, target\u001b[39m.\u001b[39;49mview(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m))\u001b[39m.\u001b[39msqueeze(\u001b[39m1\u001b[39m))\u001b[39m.\u001b[39mshape\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Size does not match at dimension 0 expected index [352, 1] to be smaller than self [32, 4039] apart from dimension 1"
     ]
    }
   ],
   "source": [
    "input = decoder_output\n",
    "target = sample_target\n",
    "torch.log(torch.gather(input, 1, target.view(-1, 1)).squeeze(1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 11])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.shape, target.shape\n",
    "torch.log(torch.gather(input, 1, target)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "out = torch.rand(32, 1000)\n",
    "print(torch.argmax(out, dim=1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_variable, lengths, target_variable, mask, max_target_len, encoder, decoder,\n",
    "          encoder_optimizer, decoder_optimizer, batch_size, clip, device='cpu'):\n",
    "\n",
    "    # Zero gradients\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    # Set device options\n",
    "    input_variable = input_variable.to(device)\n",
    "    target_variable = target_variable.to(device)\n",
    "    mask = mask.to(device)\n",
    "    # Lengths for rnn packing should always be on the cpu\n",
    "    lengths = lengths.to(\"cpu\")\n",
    "\n",
    "    # Initialize variables\n",
    "    loss = 0\n",
    "    print_losses = []\n",
    "    n_totals = 0\n",
    "\n",
    "    # Forward pass through encoder\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, lengths)\n",
    "\n",
    "    # Create initial decoder input (start with SOS tokens for each sentence)\n",
    "    decoder_input = torch.LongTensor([[1 for _ in range(batch_size)]])\n",
    "    decoder_input = decoder_input.to(device)\n",
    "\n",
    "    # Set initial decoder hidden state to the encoder's final hidden state\n",
    "    decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
    "\n",
    "    # Determine if we are using teacher forcing this iteration\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    # Forward batch of sequences through decoder one time step at a time\n",
    "    if use_teacher_forcing:\n",
    "        for t in range(max_target_len):\n",
    "            # print('TURN', t)\n",
    "            # print('hidden shape', decoder_hidden.shape)\n",
    "            # print('input', decoder_input.shape)\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            # Teacher forcing: next input is current target\n",
    "            decoder_input = target_variable.reshape(-1, batch_size)[t].unsqueeze(0)\n",
    "            # Calculate and accumulate loss\n",
    "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
    "            loss += mask_loss\n",
    "            print(mask_loss)\n",
    "            print_losses.append(mask_loss.item() * nTotal)\n",
    "            n_totals += nTotal\n",
    "    else:\n",
    "        # print('????')\n",
    "        for t in range(max_target_len):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            # No teacher forcing: next input is decoder's own current output\n",
    "            _, topi = decoder_output.topk(1)\n",
    "            decoder_input = torch.LongTensor([[topi[i][0] for i in range(batch_size)]])\n",
    "            decoder_input = decoder_input.to(device)\n",
    "            # Calculate and accumulate loss\n",
    "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
    "            loss += mask_loss\n",
    "            print_losses.append(mask_loss.item() * nTotal)\n",
    "            n_totals += nTotal\n",
    "\n",
    "    # Perform backpropatation\n",
    "    loss.backward()\n",
    "\n",
    "    # # Clip gradients: gradients are modified in place\n",
    "    # _ = nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
    "    # _ = nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
    "\n",
    "    # Adjust model weights\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return sum(print_losses) / n_totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_variable, lengths, target_variable, mask, encoder, decoder,\n",
    "          encoder_optimizer, decoder_optimizer, batch_size, clip, device='cpu'):\n",
    "\n",
    "      #input and optimizer\n",
    "      if device == 'cuda':\n",
    "        input_variable, target_variable = input_variable.to(device), target_variable.to(device)\n",
    "        encoder.cuda()\n",
    "        decoder.cuda()\n",
    "      decoder_input = torch.tensor([[1] for i in range(batch_size)], dtype=torch.long).reshape(1, -1)\n",
    "      encoder_optimizer.zero_grad()\n",
    "      decoder_optimizer.zero_grad() \n",
    "\n",
    "      #feed to model\n",
    "      #encoder:\n",
    "      encoder_output, encoder_hidden = encoder(input_variable, lengths)\n",
    "      #repeat the final hidden according to the num_layers of encoder \n",
    "      decoder_hidden = repeat(encoder_hidden[-1], 'b h -> n b h', n=decoder.n_layers)\n",
    "\n",
    "      total_loss = 0\n",
    "      n_total = 0\n",
    "      #target shape 11 x 32 (seq x batch)\n",
    "      teacher_forcing = random.uniform(0, 1) > 0.5\n",
    "      for i in range(target_variable.shape[0]): \n",
    "          decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_output)\n",
    "          if teacher_forcing:\n",
    "            decoder_input = target_variable[i].reshape(1, batch_size) #target seq x batch\n",
    "          else:\n",
    "            decoder_input = torch.argmax(decoder_output, dim=1).reshape(1, batch_size) # seq 1 x batch 32 \n",
    "  \n",
    "          loss, ntotal = maskNLLLoss(decoder_output, target_variable[i].reshape(batch_size, 1), mask)\n",
    "          total_loss += loss\n",
    "          n_total += ntotal\n",
    "      \n",
    "      #backward\n",
    "      loss.backward()\n",
    "\n",
    "      #step\n",
    "      encoder_optimizer.step()\n",
    "      decoder_optimizer.step()\n",
    "\n",
    "      return total_loss/n_total\n",
    "\n",
    "        \n",
    "            \n",
    "           \n",
    "            \n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip = 50.0\n",
    "teacher_forcing_ratio = 1.0\n",
    "learning_rate = 0.0001\n",
    "decoder_learning_ratio = 5.0\n",
    "n_iteration = 4000\n",
    "print_every = 1\n",
    "save_every = 500\n",
    "sample_input = sample_input.reshape(-1, 32)\n",
    "sample_target = sample_target.reshape(-1, 32)\n",
    "encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n",
    "# train(sample_input, lengths, sample_target, mask, encoder, decoder, encoder_optimizer, decoder_optimizer, 32, clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss = []\n",
    "for batch in dataloader:\n",
    "    sample_input, sample_target, lengths, mask = batch\n",
    "    if sample_input.shape[0] == 30:\n",
    "        \n",
    "        sample_input = sample_input.reshape(-1, 30)\n",
    "        sample_target = sample_target.reshape(-1, 30)\n",
    "        total_loss.append(train(sample_input, lengths, sample_target, mask, encoder, decoder, encoder_optimizer, decoder_optimizer, 30, clip).detach().numpy())\n",
    "    else:\n",
    "        print(sample_input.shape[0])\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=30, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LuongAttnDecoderRNN(\n",
       "  (embedding): Embedding(4039, 500)\n",
       "  (embedding_dropout): Dropout(p=0.1, inplace=False)\n",
       "  (gru): GRU(500, 500, num_layers=2, dropout=0.1)\n",
       "  (concat): Linear(in_features=1000, out_features=500, bias=True)\n",
       "  (out): Linear(in_features=500, out_features=4039, bias=True)\n",
       "  (attn): Attn()\n",
       ")"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.eval()\n",
    "decoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, input_variable, lengths, MAX_LENGTH=11):\n",
    "    decoder_input = torch.tensor([1], dtype=torch.long).reshape(1, 1)\n",
    "    encoder_output, encoder_hidden = encoder(input_variable, lengths)\n",
    "    decoder_hidden = repeat(encoder_hidden[-1], 'b h -> n b h', n=decoder.n_layers)\n",
    "    print(encoder_output.shape, decoder_hidden.shape)\n",
    "    out_token = []\n",
    "    for i in range(MAX_LENGTH):\n",
    "        decoder_ouput, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_output)\n",
    "        out_token.append(torch.argmax(decoder_ouput, dim=1))\n",
    "        decoder_input = torch.argmax(decoder_ouput, dim=1).reshape(1, 1)\n",
    "    \n",
    "    return out_token\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1130,   24, 1058,   23,    2])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = 'hello my name is'\n",
    "\n",
    "\n",
    "word_tensor = torch.tensor([vocab.word2idx[i] for i in word.split()] + [vocab.word2idx['EOS']], dtype=torch.long)\n",
    "word_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(word.split()) < 11:\n",
    "          word_tensor = torch.cat([word_tensor, torch.zeros(10 - len(input.split()), dtype=torch.long)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11, 1])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tensor = word_tensor.reshape(-1, 1)\n",
    "word_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 500]) torch.Size([2, 1, 500])\n"
     ]
    }
   ],
   "source": [
    "out_token = evaluate(encoder, decoder, word_tensor, torch.tensor([len(word.split())]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = ''\n",
    "for i in out_token:\n",
    "    sentence += vocab.idx2word[i.item()] + ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'learn learn days iksetkiba one one one one one approaching one '"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "73fdcbcaa6b22d852c0f9bd9783ab6b1b1c25c52a0a8da76beae07513436cb85"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('deeplearning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
