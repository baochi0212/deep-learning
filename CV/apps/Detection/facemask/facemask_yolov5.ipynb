{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "My_YOLOV5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMWSmvhkgsd7sSoLw5Ei2/9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/baochi0212/facemask/blob/master/My_YOLOV5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The prev facemask use the retina net(pyramid)"
      ],
      "metadata": {
        "id": "vaI51E9GYNP7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9_zfiNDYE5d",
        "outputId": "d08b4023-bda8-4dd9-9042-9d191a326bd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 10878, done.\u001b[K\n",
            "remote: Total 10878 (delta 0), reused 0 (delta 0), pack-reused 10878\u001b[K\n",
            "Receiving objects: 100% (10878/10878), 10.96 MiB | 19.35 MiB/s, done.\n",
            "Resolving deltas: 100% (7512/7512), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ultralytics/yolov5"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r /content/yolov5/requirements.txt"
      ],
      "metadata": {
        "id": "8NY4i0DQbnmy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Pseudo-Lab/Tutorial-Book-Utils\n",
        "!python Tutorial-Book-Utils/PL_data_loader.py --data FaceMaskDetection\n",
        "!unzip -q Face\\ Mask\\ Detection.zip"
      ],
      "metadata": {
        "id": "0jwvLlX1bvP6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81cb51bf-d625-4f27-903a-213aadead7b4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Tutorial-Book-Utils'...\n",
            "remote: Enumerating objects: 30, done.\u001b[K\n",
            "remote: Counting objects: 100% (30/30), done.\u001b[K\n",
            "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
            "remote: Total 30 (delta 9), reused 18 (delta 5), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (30/30), done.\n",
            "Face Mask Detection.zip is done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import shutil\n",
        "\n",
        "print(len(os.listdir('annotations')))\n",
        "print(len(os.listdir('images')))\n",
        "\n",
        "!mkdir test_images\n",
        "!mkdir test_annotations\n",
        "\n",
        "\n",
        "random.seed(1234)\n",
        "idx = random.sample(range(853), 170)\n",
        "\n",
        "for img in np.array(sorted(os.listdir('images')))[idx]:\n",
        "    shutil.move('images/'+img, 'test_images/'+img)\n",
        "\n",
        "for annot in np.array(sorted(os.listdir('annotations')))[idx]:\n",
        "    shutil.move('annotations/'+annot, 'test_annotations/'+annot)\n",
        "\n",
        "print(len(os.listdir('annotations')))\n",
        "print(len(os.listdir('images')))\n",
        "print(len(os.listdir('test_annotations')))\n",
        "print(len(os.listdir('test_images')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yflEplU8HIM",
        "outputId": "3b88cde9-b729-402e-ba05-b64d577780de"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "853\n",
            "853\n",
            "683\n",
            "683\n",
            "170\n",
            "170\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.patches as patches\n",
        "from bs4 import BeautifulSoup\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import numpy as np\n",
        "import time\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "from matplotlib import pyplot as plt\n",
        "import os\n",
        "\n",
        "def generate_box(obj):\n",
        "    \n",
        "    xmin = float(obj.find('xmin').text)\n",
        "    ymin = float(obj.find('ymin').text)\n",
        "    xmax = float(obj.find('xmax').text)\n",
        "    ymax = float(obj.find('ymax').text)\n",
        "    \n",
        "    return [xmin, ymin, xmax, ymax]\n",
        "\n",
        "def generate_label(obj):\n",
        "\n",
        "    if obj.find('name').text == \"with_mask\":\n",
        "\n",
        "        return 1\n",
        "\n",
        "    elif obj.find('name').text == \"mask_weared_incorrect\":\n",
        "\n",
        "        return 2\n",
        "\n",
        "    return 0\n",
        "\n",
        "def generate_target(file): \n",
        "    with open(file) as f:\n",
        "        data = f.read()\n",
        "        soup = BeautifulSoup(data, \"html.parser\")\n",
        "        objects = soup.find_all(\"object\")\n",
        "\n",
        "        num_objs = len(objects)\n",
        "\n",
        "        boxes = []\n",
        "        labels = []\n",
        "        for i in objects:\n",
        "            boxes.append(generate_box(i))\n",
        "            labels.append(generate_label(i))\n",
        "\n",
        "        boxes = torch.as_tensor(boxes, dtype=torch.float32) \n",
        "        labels = torch.as_tensor(labels, dtype=torch.int64) \n",
        "        \n",
        "        target = {}\n",
        "        target[\"boxes\"] = boxes\n",
        "        target[\"labels\"] = labels\n",
        "        \n",
        "        return target\n",
        "\n",
        "def plot_image_from_output(img, annotation):\n",
        "    \n",
        "    img = img.cpu().permute(1,2,0)\n",
        "    \n",
        "    rects = []\n",
        "\n",
        "    for idx in range(len(annotation[\"boxes\"])):\n",
        "        xmin, ymin, xmax, ymax = annotation[\"boxes\"][idx]\n",
        "\n",
        "        if annotation['labels'][idx] == 0 :\n",
        "            rect = patches.Rectangle((xmin,ymin),(xmax-xmin),(ymax-ymin),linewidth=1,edgecolor='r',facecolor='none')\n",
        "        \n",
        "        elif annotation['labels'][idx] == 1 :\n",
        "            \n",
        "            rect = patches.Rectangle((xmin,ymin),(xmax-xmin),(ymax-ymin),linewidth=1,edgecolor='g',facecolor='none')\n",
        "            \n",
        "        else :\n",
        "        \n",
        "            rect = patches.Rectangle((xmin,ymin),(xmax-xmin),(ymax-ymin),linewidth=1,edgecolor='orange',facecolor='none')\n",
        "\n",
        "        rects.append(rect)\n",
        "\n",
        "    return img, rects\n",
        "\n",
        "class MaskDataset(Dataset):\n",
        "    def __init__(self, path, transform=None):\n",
        "        self.path = path\n",
        "        self.imgs = list(sorted(os.listdir(self.path)))\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.imgs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        file_image = self.imgs[idx]\n",
        "        file_label = self.imgs[idx][:-3] + 'xml'\n",
        "        img_path = os.path.join(self.path, file_image)\n",
        "        \n",
        "        if 'test' in self.path:\n",
        "            label_path = os.path.join(\"test_annotations/\", file_label)\n",
        "        else:\n",
        "            label_path = os.path.join(\"annotations/\", file_label)\n",
        "\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        target = generate_target(label_path)\n",
        "        \n",
        "        to_tensor = torchvision.transforms.ToTensor()\n",
        "\n",
        "        if self.transform:\n",
        "            img, transform_target = self.transform(np.array(img), np.array(target['boxes']))\n",
        "            target['boxes'] = torch.as_tensor(transform_target)\n",
        "\n",
        "        # change to tensor\n",
        "        img = to_tensor(img)\n",
        "\n",
        "\n",
        "        return img, target\n",
        "\n",
        "def collate_fn(batch):\n",
        "    return tuple(zip(*batch))\n",
        "\n",
        "dataset = MaskDataset('images/')\n",
        "test_dataset = MaskDataset('test_images/')\n",
        "\n",
        "data_loader = torch.utils.data.DataLoader(dataset, batch_size=4, collate_fn=collate_fn)\n",
        "test_data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=2, collate_fn=collate_fn)\n"
      ],
      "metadata": {
        "id": "4LT1vipEBJU7"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = [[1,2,3], [4,5,6]]\n",
        "print(list(zip(*a)))\n",
        "#* take a as combination of list zip(a, b) not zip(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1s1p0Z5_L13z",
        "outputId": "ab72ca67-ab09-4c79-b582-c017a1bdd9ec"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(1, 4), (2, 5), (3, 6)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iter(data_loader).next()[1][0], iter(data_loader).next()[0][0].shape\n",
        "#format: data - label(boxes, labels(binary))\n",
        "#different size so we have to pass the custom collate_fn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbP1PUfUBNM4",
        "outputId": "e8657163-08d2-47bf-ffa8-d9f584774939"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'boxes': tensor([[ 79., 105., 109., 142.],\n",
              "          [185., 100., 226., 144.],\n",
              "          [325.,  90., 360., 141.]]), 'labels': tensor([0, 1, 0])},\n",
              " torch.Size([3, 366, 512]))"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[1][0].shape, dataset[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBuab1WFJdMa",
        "outputId": "af04c2c8-d66c-46b1-ec81-c6046dd96429"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3, 156, 400]),\n",
              " tensor([[[0.4431, 0.4314, 0.3843,  ..., 0.1569, 0.2824, 0.3373],\n",
              "          [0.4118, 0.3882, 0.3451,  ..., 0.1529, 0.1882, 0.3098],\n",
              "          [0.3765, 0.3569, 0.3255,  ..., 0.1490, 0.1216, 0.2784],\n",
              "          ...,\n",
              "          [0.3333, 0.3412, 0.3569,  ..., 0.1098, 0.1098, 0.1137],\n",
              "          [0.3373, 0.3490, 0.3608,  ..., 0.1137, 0.1137, 0.1176],\n",
              "          [0.3647, 0.3765, 0.3922,  ..., 0.1176, 0.1176, 0.1216]],\n",
              " \n",
              "         [[0.4353, 0.4235, 0.3765,  ..., 0.2314, 0.3843, 0.4549],\n",
              "          [0.3922, 0.3804, 0.3373,  ..., 0.2275, 0.2863, 0.4275],\n",
              "          [0.3608, 0.3412, 0.3098,  ..., 0.2235, 0.2235, 0.3922],\n",
              "          ...,\n",
              "          [0.3255, 0.3333, 0.3490,  ..., 0.1059, 0.1059, 0.1098],\n",
              "          [0.3294, 0.3412, 0.3529,  ..., 0.1098, 0.1098, 0.1137],\n",
              "          [0.3569, 0.3686, 0.3843,  ..., 0.1137, 0.1137, 0.1176]],\n",
              " \n",
              "         [[0.4549, 0.4431, 0.3961,  ..., 0.4000, 0.6157, 0.7294],\n",
              "          [0.4157, 0.3922, 0.3490,  ..., 0.3843, 0.5059, 0.6784],\n",
              "          [0.3647, 0.3451, 0.3137,  ..., 0.3529, 0.4118, 0.6157],\n",
              "          ...,\n",
              "          [0.3451, 0.3529, 0.3608,  ..., 0.1255, 0.1255, 0.1294],\n",
              "          [0.3490, 0.3608, 0.3725,  ..., 0.1294, 0.1294, 0.1333],\n",
              "          [0.3765, 0.3882, 0.4039,  ..., 0.1333, 0.1333, 0.1373]]]))"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use roboflow to convert to yolov5 coco\n"
      ],
      "metadata": {
        "id": "hyTlbSVoYWOo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"QlPOQtcxpcmV25dVhFGb\")\n",
        "project = rf.workspace().project(\"face_mask-oxref\")\n",
        "dataset = project.version(1).download(\"yolov5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9W7bUjTMWVt",
        "outputId": "a99aef81-0c75-49a4-d159-e226547ecbf2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: roboflow in /usr/local/lib/python3.7/dist-packages (0.2.2)\n",
            "Requirement already satisfied: opencv-python>=4.1.2 in /usr/local/lib/python3.7/dist-packages (from roboflow) (4.1.2.30)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.7/dist-packages (from roboflow) (0.19.2)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from roboflow) (7.1.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from roboflow) (1.19.5)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.7/dist-packages (from roboflow) (6.0)\n",
            "Requirement already satisfied: cycler==0.10.0 in /usr/local/lib/python3.7/dist-packages (from roboflow) (0.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from roboflow) (1.15.0)\n",
            "Requirement already satisfied: idna==2.10 in /usr/local/lib/python3.7/dist-packages (from roboflow) (2.10)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from roboflow) (3.2.2)\n",
            "Requirement already satisfied: pyparsing==2.4.7 in /usr/local/lib/python3.7/dist-packages (from roboflow) (2.4.7)\n",
            "Requirement already satisfied: urllib3==1.26.6 in /usr/local/lib/python3.7/dist-packages (from roboflow) (1.26.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from roboflow) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from roboflow) (4.62.3)\n",
            "Requirement already satisfied: kiwisolver==1.3.1 in /usr/local/lib/python3.7/dist-packages (from roboflow) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from roboflow) (2.8.2)\n",
            "Requirement already satisfied: wget in /usr/local/lib/python3.7/dist-packages (from roboflow) (3.2)\n",
            "Requirement already satisfied: certifi==2021.5.30 in /usr/local/lib/python3.7/dist-packages (from roboflow) (2021.5.30)\n",
            "Requirement already satisfied: chardet==4.0.0 in /usr/local/lib/python3.7/dist-packages (from roboflow) (4.0.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests->roboflow) (2.0.11)\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Downloading Dataset Version Zip in face_mask-1 to yolov5pytorch: 100% [22191739 / 22191739] bytes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Dataset Version Zip to face_mask-1 in yolov5pytorch:: 100%|██████████| 1708/1708 [00:01<00:00, 1099.99it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ultralytics/yolov5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mCO0o7sVQt5",
        "outputId": "15740c80-3547-4a73-aaa0-dbb7707ffc8f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 10882, done.\u001b[K\n",
            "remote: Total 10882 (delta 0), reused 0 (delta 0), pack-reused 10882\u001b[K\n",
            "Receiving objects: 100% (10882/10882), 10.92 MiB | 26.94 MiB/s, done.\n",
            "Resolving deltas: 100% (7524/7524), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd yolov5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68zVgdeWYlSb",
        "outputId": "6c681861-3e45-4a1f-8d5f-e0c9437f24dc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#run yolo\n",
        "!python train.py --img 416 --batch 16 --epochs 150 --data /content/yolov5/face_mask-1/data.yaml --weights /content/yolov5s.pt --cache"
      ],
      "metadata": {
        "id": "rz8_5e8MVlje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --weights runs/train/exp/weights/best.pt --img 416 --conf 0.1 --source /content/yolov5/face_mask-1/test/images"
      ],
      "metadata": {
        "id": "hrzf9595Yipz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob\n",
        "from IPython.display import Image, display\n",
        "\n",
        "for image in glob('/content/yolov5/runs/detect/exp/*.jpg'):\n",
        "  display(Image(image))\n",
        "  print()\n",
        "  \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZG6JXyZPY5Xc",
        "outputId": "597be20d-5c50-431a-eead-a93aab841b5b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/yolov5/face_mask-1/test/images/maksssksksss2_png.rf.1b54188e1ac11bc0c0b6cd02bc7a0d0d.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss48_png.rf.3c9c7edc119b02416025394f77598b4a.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss664_png.rf.6b5866f9176d68ee1a01438c2ce99e2f.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss844_png.rf.34d5979504863e738582be2fa1a10594.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss840_png.rf.c13a9c9de6fe0dfcda206c81c94001c8.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss197_png.rf.2be6db9a470681e6873422f4efc3fe73.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss278_png.rf.054e88571a82505f649e10ba7e94edbb.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss265_png.rf.e812dfb43b3e980b58782b6508b1cb0e.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss670_png.rf.dae672cd1aa53a15e0fde60dce675f23.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss451_png.rf.47d208f5bff614acf24c67c3a1912e87.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss443_png.rf.5860047276dfe833ff69c7904a1b6bd6.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss244_png.rf.bb8bda1694e5eda0fa31f5b762c441ca.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss789_png.rf.3b5b33521b3f3bc80176771148c83277.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss809_png.rf.279fb4f5adc2b305576cb15da7b9fb0a.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss774_png.rf.c222cb90168f3ea5cf779219907420aa.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss348_png.rf.90344538f4bb08348f6ddabb00e7279e.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss534_png.rf.b7873dd8619549671317a09b07cfb33c.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss727_png.rf.a0074775dae414d07da973dd2554ccde.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss793_png.rf.eee3036dd8d94aaba68111081ab071d5.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss752_png.rf.492521a5b9795f94d3559bb4c9c9c0b7.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss4_png.rf.d6685c23a80bf95c8ad6387fde1479c9.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss192_png.rf.16172c20d2529e8614dc0c2f421b4cea.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss614_png.rf.8ad748bccd8103852a2f64ea699a2baa.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss127_png.rf.ab8725b43b9c6de3d0a6ca0a9adf087e.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss830_png.rf.3dbe342f77850735c44247a1b7889d80.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss831_png.rf.977ffcebb3debe3ccd475782cbdb69be.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss786_png.rf.7c3907eab7f8170a0da277a3905dbf99.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss314_png.rf.1c976f1f0fc0c2f3a745c86360c6a68d.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss239_png.rf.d89ce9fcced31a64e93f6454e54301aa.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss778_png.rf.1a45602d3d818b7ef5f446678d038ee4.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss343_png.rf.ff387257da7b8417afbed709da37887e.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss203_png.rf.8272a63ca2bfda3d78d67d398a98ce40.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss34_png.rf.e56f03613491f98df5a37ca2b125f548.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss464_png.rf.66034ef7ef0770e57f12386d1ce4fadc.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss121_png.rf.fdc7ec902c96784cc27ae6452ce92306.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss24_png.rf.96ab1083a36b39d5edc7248de3454aa3.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss511_png.rf.66664bf1cd15624a9f8a23fb35c8167b.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss538_png.rf.481b48d6a0b0aa717363af9e469ad56a.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss808_png.rf.3d37a46c59d704fe15d9fbab8e1477b2.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss362_png.rf.2cb7dc0c2c294f75046c893120473729.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss40_png.rf.c8a154a20dc4d6c64d16ada67ae2d233.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss116_png.rf.48a8a3c7e1202a67c4c9143f30fc0f81.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss608_png.rf.802727eabadb600588e91ce5bca8a742.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss150_png.rf.81f0f6ae3b3e65f2b2f4c3c17a297b02.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss259_png.rf.142b57fbb7cce41cf58485b246ac2dc6.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss637_png.rf.00f9b8df50a53a52de4ab1587a9389e4.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss392_png.rf.914ea1c4052701621c8d3b90729dca20.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss300_png.rf.a15a69aaed8529e3933b3c13b0538aab.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss802_png.rf.344d15b6635fec87366adb3cb5d59cea.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss258_png.rf.d4adc41a6e0e3d732870aa446869572a.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss650_png.rf.aed94756bb8c4bbd9d40a4329e05f945.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss366_png.rf.ffdc5ff45fb14c282ae3f3d8fe8784c9.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss266_png.rf.5ac2f5977e66f42b8bd5189f1f39e25f.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss469_png.rf.fcff53b222892cdbd2af65db79ed0df6.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss175_png.rf.34c31d0140f7b8d131728a2c9d3e4b05.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss628_png.rf.e7a8f31e7bf039618e4fcbd35138695e.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss814_png.rf.e1c866eef0a27c6485b70b4b10918726.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss498_png.rf.d37a516be627bd1c9bed905b235ccd00.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss390_png.rf.95908f467d1f593a802bd068d1495723.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss198_png.rf.1e53e9c79cb6232d2f05928dbe6eceee.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss295_png.rf.ade800c6c3597d1ffb2424f0c1692ad5.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss253_png.rf.ae88a08c1758fe6dded56bab192fec17.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss796_png.rf.bb0caf78a2d84922b721d8334c926f23.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss630_png.rf.73a666ee83fc603acf6f19eb4e6d5d9b.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss51_png.rf.f94c9ecf4e70a3a7a37f87aba14129b0.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss213_png.rf.286bbfc295263f993105502e1c11fe0d.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss240_png.rf.1e9b633cbd7748b2c70e69995d0f0202.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss122_png.rf.a57844cf72e43ddb58c3b5cdb5c285c7.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss457_png.rf.d7c6fbede0a6a289b88912df334b98db.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss220_png.rf.fc3930b446f97e33db44f1ddf0574124.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss111_png.rf.a6c5c1da16624f479adf384126cc9590.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss32_png.rf.2205e08b8296db38b423bddbcd82dcca.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss617_png.rf.471b5746c8239e90dd322a7fdcf529b9.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss594_png.rf.47a92649405d2ffde13865b32bdda24b.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss113_png.rf.e27a159aa9ea39278db92ef0bda23898.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss800_png.rf.faebb1b3324241948a861768c0368130.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss764_png.rf.4f5615450149212172b27069beddd119.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss672_png.rf.2ebc4e478b7229399c2f81780f6ea9f5.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss182_png.rf.4787af2babf41ee8e832ba4494ff30bd.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss788_png.rf.2d2990c4271501cfaaf7bacbd1eb3de3.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss352_png.rf.72e8d07e6701931de2983226b1a53c38.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss424_png.rf.d81d59c520017a27badf5efc322d4645.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss452_png.rf.c7a372af0117488b1b864fa1825ff569.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss429_png.rf.f819af5cf2dd9e4193f0319ceb9f88b5.jpg',\n",
              " '/content/yolov5/face_mask-1/test/images/maksssksksss779_png.rf.8f439c8641299f0b2ee5ccc44b4eee3e.jpg']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ]
}