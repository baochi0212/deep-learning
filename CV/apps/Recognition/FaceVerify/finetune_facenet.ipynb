{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmF9dZK1dJCl"
      },
      "source": [
        "# Face detection and recognition training pipeline\n",
        "\n",
        "The following example illustrates how to fine-tune an InceptionResnetV1 model on your own dataset. This will mostly follow standard pytorch training patterns."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/timesler/facenet-pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HBftUSgdN-k",
        "outputId": "30aa79ea-bcfe-4652-d121-1830f0db1b3f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'facenet-pytorch'...\n",
            "remote: Enumerating objects: 1267, done.\u001b[K\n",
            "remote: Total 1267 (delta 0), reused 0 (delta 0), pack-reused 1267\u001b[K\n",
            "Receiving objects: 100% (1267/1267), 22.88 MiB | 17.17 MiB/s, done.\n",
            "Resolving deltas: 100% (620/620), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q facenet_pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oi-R6g5vdR3B",
        "outputId": "a8bb6414-7918-4dbc-face-1742618ccf7b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |▏                               | 10 kB 18.6 MB/s eta 0:00:01\r\u001b[K     |▍                               | 20 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |▌                               | 30 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |▊                               | 40 kB 3.4 MB/s eta 0:00:01\r\u001b[K     |▉                               | 51 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |█                               | 61 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 71 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 81 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 92 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 102 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██                              | 112 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██                              | 122 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 133 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 143 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 153 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 163 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███                             | 174 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 184 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 194 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 204 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 215 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 225 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████                            | 235 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 245 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 256 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 266 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 276 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 286 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████                           | 296 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 307 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 317 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 327 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 337 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████                          | 348 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████                          | 358 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 368 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 378 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 389 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 399 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████                         | 409 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 419 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 430 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 440 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 450 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 460 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████                        | 471 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 481 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 491 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 501 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 512 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 522 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 532 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 542 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 552 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 563 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 573 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 583 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 593 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 604 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 614 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 624 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 634 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 645 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 655 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 665 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 675 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 686 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 696 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 706 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 716 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 727 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 737 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 747 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 757 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 768 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 778 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 788 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 798 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 808 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 819 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 829 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 839 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 849 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 860 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 870 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 880 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 890 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 901 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 911 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 921 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 931 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 942 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 952 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 962 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 972 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 983 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 993 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.0 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 1.0 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 1.0 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 1.0 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 1.0 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.1 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.1 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 1.1 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 1.1 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 1.1 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 1.1 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.1 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 1.1 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 1.1 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 1.1 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 1.2 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 1.2 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.2 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 1.2 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 1.2 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 1.2 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 1.2 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 1.2 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.2 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.2 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 1.3 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 1.3 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 1.3 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.3 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.3 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.3 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 1.3 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.3 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.3 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.4 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.4 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 1.4 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.4 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.4 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.4 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.4 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.4 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.4 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.4 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.5 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 1.5 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.5 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.5 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.5 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.5 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.5 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.5 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.5 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.5 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.6 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.6 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.6 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.6 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.6 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.6 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.6 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.6 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.6 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.6 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.7 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.7 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.7 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.7 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.7 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.7 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.7 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.7 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 1.7 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.8 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.8 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.8 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.8 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.8 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.8 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.8 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.8 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.8 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.8 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.9 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.9 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.9 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.9 MB 4.2 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zlq3GC6dJCu",
        "outputId": "86be41bf-ff61-4ce0-aecb-c0f3db4888ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/facenet-pytorch\n"
          ]
        }
      ],
      "source": [
        "from facenet_pytorch import MTCNN, InceptionResnetV1, fixed_image_standardization, training\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
        "from torch import optim\n",
        "from torch.optim.lr_scheduler import MultiStepLR\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import os\n",
        "%cd /content/facenet-pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3n4OxP-dJCw"
      },
      "source": [
        "#### Define run parameters\n",
        "\n",
        "The dataset should follow the VGGFace2/ImageNet-style directory layout. Modify `data_dir` to the location of the dataset on wish to finetune on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "qBOElF5CdJCx"
      },
      "outputs": [],
      "source": [
        "data_dir = 'data/test_images'\n",
        "\n",
        "batch_size = 32\n",
        "epochs = 8\n",
        "workers = 0 if os.name == 'nt' else 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_yP_K0kdJCy"
      },
      "source": [
        "#### Determine if an nvidia GPU is available"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7cWZw3wdJCy",
        "outputId": "5a79f727-ed5c-45c0-c5b6-44e86c2f9eab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on device: cpu\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print('Running on device: {}'.format(device))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKjFrxp1dJCz"
      },
      "source": [
        "#### Define MTCNN module\n",
        "\n",
        "See `help(MTCNN)` for more details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Et6O9jCodJC0"
      },
      "outputs": [],
      "source": [
        "mtcnn = MTCNN(\n",
        "    image_size=160, margin=0, min_face_size=20,\n",
        "    thresholds=[0.6, 0.7, 0.7], factor=0.709, post_process=True,\n",
        "    device=device\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHnnOPNmdJC2"
      },
      "source": [
        "#### Perfom MTCNN facial detection\n",
        "\n",
        "Iterate through the DataLoader object and obtain cropped faces."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.elleman.vn/wp-content/uploads/2019/06/03/Angelina-Jolie-elle-man-featured-image.jpg -q -P /content/facenet-pytorch/data/test_images/angelina_jolie\n",
        "!wget https://vcdn1-giaitri.vnecdn.net/2021/08/25/Angelina-Jolie-top-6702-1629859385.jpg?w=0&h=0&q=100&dpr=2&fit=crop&s=bPiM7bSi9ws-oOax4Y4Uew -q -P /content/facenet-pytorch/data/test_images/angelina_jolie\n",
        "!wget https://storage0.dms.mpinteractiv.ro/media/401/341/5531/16234353/1/jolie-1.jpg?width=310 -q -P /content/facenet-pytorch/data/test_images/angelina_jolie\n",
        "!wget https://vcdn1-giaitri.vnecdn.net/2021/08/25/Angelina-Jolie-top-6702-1629859385.jpg?w=0&h=0&q=100&dpr=2&fit=crop&s=bPiM7bSi9ws-oOax4Y4Uew -q -P /content/facenet-pytorch/data/test_images/angelina_jolie\n",
        "!wget https://www.etonline.com/sites/default/files/styles/max_1280x720/public/images/2015-06/set_angelina_jolie_red_carpet_640.jpg?itok=SzToquIy -q -P /content/facenet-pytorch/data/test_images/angelina_jolie\n",
        "!wget https://thumbs.dreamstime.com/b/angelina-jolie-angelina-jolie-26357396.jpg -q -P /content/facenet-pytorch/data/test_images/angelina_jolie\n"
      ],
      "metadata": {
        "id": "CQdycEplihpB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget \"https://kenh14cdn.com/2020/6/4/angelina-jolie-1591262333644618329469.jpg\" -q -P /content/facenet-pytorch/data/test_images/angelina_jolie\n",
        "!wget \"https://www.brides.com/thmb/efO7gj4mf1VDSWNPzX_VSc1ccKQ=/735x0/__opt__aboutcom__coeus__resources__content_migration__brides__public__brides-services__production__2016__10__24__580e6810382731317ade0896_blogs-aisle-say-angelina-jolie-weddings-main-64698e4cdeb64c07a8b53f4990e95173.jpg\" -q -P /content/facenet-pytorch/data/test_images/angelina_jolie\n"
      ],
      "metadata": {
        "id": "HurQNslvmMTw"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://static-znews.zadn.vn/static/topic/person/bradley.jpg -q -P /content/facenet-pytorch/data/test_images/bradley_cooper\n",
        "!wget https://media-cdn-v2.laodong.vn/Storage/NewsPortal/2022/6/18/1057851/Image.jpeg -q -P /content/facenet-pytorch/data/test_images/bradley_cooper\n",
        "!wget https://phantom-marca.unidadeditorial.es/0aabd91083ebf7980b25a4579f7ac333/resize/1320/f/jpg/assets/multimedia/imagenes/2022/06/17/16554758566395.jpg -q -P /content/facenet-pytorch/data/test_images/bradley_cooper\n",
        "!wget https://img.etimg.com/thumb/width-1200,height-900,imgsize-56168,resizemode-1,msid-91923282/news/international/us/bradley-cooper-plays-leonard-bernstein-in-the-biopic-maestro-and-is-unrecognisable.jpg -q -P /content/facenet-pytorch/data/test_images/bradley_cooper\n",
        "!wget https://www.indiewire.com/wp-content/uploads/2022/06/Bradley-Cooper.jpg -q -P /content/facenet-pytorch/data/test_images/bradley_cooper\n"
      ],
      "metadata": {
        "id": "9MS8pkFMjAwz"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://cdn-aiogc.nitrocdn.com/rMYQrsZdIIazKavgLMeJFjBGGJYSrQyJ/assets/static/optimized/rev-66a7702/wp-content/uploads/2021/12/kate-siegel-header.jpg -q -P /content/facenet-pytorch/data/test_images/kate_siegel\n",
        "!wget https://m.media-amazon.com/images/M/MV5BYTRhZGYzZDAtMDQ0MC00ZjVmLTkwN2ItYjk3NTRmNGJkMWY1XkEyXkFqcGdeQXVyNTQ1NTQyNjk@._V1_.jpg -q -P /content/facenet-pytorch/data/test_images/kate_siegel\n",
        "!wget \"https://i.pinimg.com/736x/27/4b/e6/274be6bf61d81a5a7b988cf23f379f0e.jpg\" -q -P /content/facenet-pytorch/data/test_images/kate_siegel\n",
        "!wget \"https://i.pinimg.com/474x/43/b3/02/43b302d5022660454f54e42a2a14449d.jpg\" -q -P /content/facenet-pytorch/data/test_images/kate_siegel\n"
      ],
      "metadata": {
        "id": "txRC3trlkdmJ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget \"https://m.media-amazon.com/images/M/MV5BMTY4NTEwNDg1MV5BMl5BanBnXkFtZTgwODMwMDA0ODE@._V1_UY1200_CR165,0,630,1200_AL_.jpg\" -q -P /content/facenet-pytorch/data/test_images/paul_rudd\n",
        "!wget \"https://www.themoviedb.org/t/p/w500/8eTtJ7XVXY0BnEeUaSiTAraTIXd.jpg\" -q -P /content/facenet-pytorch/data/test_images/paul_rudd\n",
        "!wget \"https://deadline.com/wp-content/uploads/2016/04/paul-rudd.jpg\" -q -P /content/facenet-pytorch/data/test_images/paul_rudd\n",
        "!wget \"https://www.nj.com/resizer/JcqW0gGlMGCtkpGUGvdYKMVr248=/1280x0/smart/cloudfront-us-east-1.images.arcpublishing.com/advancelocal/W5G7TNDQFNH45I6LNTDEHOM4R4.jpg\" -q -P /content/facenet-pytorch/data/test_images/paul_rudd\n"
      ],
      "metadata": {
        "id": "Fc821egxkxFx"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget \"https://www.themoviedb.org/t/p/w500/d3caK3l4UfbnzOxv95wLoFLZzMO.jpg\" -q -P /content/facenet-pytorch/data/test_images/shea_whigham\n",
        "!wget \"https://www.purchase.edu/live/image/gid/34/width/640/3238_shea-whigham.rev.1484853205.jpg\" -q -P /content/facenet-pytorch/data/test_images/shea_whigham\n",
        "!wget \"https://1.bp.blogspot.com/-vg6GlEDvbjA/TxeJzc8hTPI/AAAAAAAACxs/jKc9q6xWujA/s1600/Shea.jpg\" -q -P /content/facenet-pytorch/data/test_images/shea_whigham\n",
        "!wget \"https://upload.wikimedia.org/wikipedia/commons/thumb/7/76/Shea_Whigham_in_2018.jpg/640px-Shea_Whigham_in_2018.jpg\" -q -P /content/facenet-pytorch/data/test_images/shea_whigham\n"
      ],
      "metadata": {
        "id": "ch_8C8fZlLcg"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEpm8JZ1dJC3",
        "outputId": "5ef8191b-1f67-4253-baf6-bfceab99d27d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rBatch 1 of 10"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/facenet_pytorch/models/utils/detect_face.py:183: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  batch_boxes, batch_points = np.array(batch_boxes), np.array(batch_points)\n",
            "/usr/local/lib/python3.7/dist-packages/facenet_pytorch/models/mtcnn.py:339: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  boxes = np.array(boxes)\n",
            "/usr/local/lib/python3.7/dist-packages/facenet_pytorch/models/mtcnn.py:340: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  probs = np.array(probs)\n",
            "/usr/local/lib/python3.7/dist-packages/facenet_pytorch/models/mtcnn.py:341: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  points = np.array(points)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 7 of 10"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/facenet_pytorch/models/mtcnn.py:444: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  selected_boxes = np.array(selected_boxes)\n",
            "/usr/local/lib/python3.7/dist-packages/facenet_pytorch/models/mtcnn.py:446: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  selected_points = np.array(selected_points)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 10 of 10"
          ]
        }
      ],
      "source": [
        "dataset = datasets.ImageFolder(data_dir, transform=transforms.Resize((512, 512)))\n",
        "dataset.samples = [\n",
        "    (p, p.replace(data_dir, data_dir + '_cropped'))\n",
        "        for p, _ in dataset.samples\n",
        "]\n",
        "        \n",
        "loader = DataLoader(\n",
        "    dataset,\n",
        "    num_workers=workers,\n",
        "    batch_size=2,\n",
        "    collate_fn=training.collate_pil\n",
        ")\n",
        "\n",
        "for i, (x, y) in enumerate(loader):\n",
        "    mtcnn(x, save_path=y)\n",
        "    print('\\rBatch {} of {}'.format(i + 1, len(loader)), end='')\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rD-vxyTdJC4"
      },
      "source": [
        "#### Define Inception Resnet V1 module\n",
        "\n",
        "See `help(InceptionResnetV1)` for more details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "ihUxiKH7dJC4"
      },
      "outputs": [],
      "source": [
        "resnet = InceptionResnetV1(\n",
        "    classify=True,\n",
        "    pretrained='vggface2',\n",
        "    num_classes=len(dataset.class_to_idx)\n",
        ").to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for params in resnet.parameters():\n",
        "  params.requires_grad_(False)\n",
        "  "
      ],
      "metadata": {
        "id": "67MZ7823qgvt"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for params in resnet.logits.parameters():\n",
        "  params.requires_grad_(True)"
      ],
      "metadata": {
        "id": "ng7dUY3arjJ1"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enLnvB2xdJC5"
      },
      "source": [
        "#### Define optimizer, scheduler, dataset, and dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "sVALPtWsdJC5"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.Adam(resnet.parameters(), lr=0.001)\n",
        "scheduler = MultiStepLR(optimizer, [5, 10])\n",
        "\n",
        "trans = transforms.Compose([\n",
        "    np.float32,\n",
        "    transforms.ToTensor(),\n",
        "    fixed_image_standardization\n",
        "])\n",
        "dataset = datasets.ImageFolder(data_dir + '_cropped', transform=trans)\n",
        "img_inds = np.arange(len(dataset))\n",
        "np.random.shuffle(img_inds)\n",
        "train_inds = img_inds[:int(0.8 * len(img_inds))]\n",
        "val_inds = img_inds[int(0.8 * len(img_inds)):]\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    dataset,\n",
        "    num_workers=workers,\n",
        "    batch_size=32,\n",
        "    sampler=SubsetRandomSampler(train_inds)\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    dataset,\n",
        "    num_workers=workers,\n",
        "    batch_size=32,\n",
        "    sampler=SubsetRandomSampler(val_inds)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXT2GQYBdJC6"
      },
      "source": [
        "#### Define loss and evaluation functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "6Odls3KqdJC6"
      },
      "outputs": [],
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "metrics = {\n",
        "    'fps': training.BatchTimer(),\n",
        "    'acc': training.accuracy\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swZQ7LmtdJC7"
      },
      "source": [
        "#### Train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "se7rh_1fdJC7",
        "outputId": "5c746c27-6bd2-46da-fad9-83f459bcb066"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Initial\n",
            "----------\n",
            "Valid |     1/1    | loss:    0.7333 | fps:    1.7296 | acc:    1.0000   \n",
            "\n",
            "Epoch 1/8\n",
            "----------\n",
            "Train |     1/1    | loss:    1.0055 | fps:    6.6870 | acc:    0.6154   \n",
            "Valid |     1/1    | loss:    0.6325 | fps:    3.7240 | acc:    1.0000   \n",
            "\n",
            "Epoch 2/8\n",
            "----------\n",
            "Train |     1/1    | loss:    0.8153 | fps:    6.6509 | acc:    0.6923   \n",
            "Valid |     1/1    | loss:    0.5416 | fps:    3.8258 | acc:    1.0000   \n",
            "\n",
            "Epoch 3/8\n",
            "----------\n",
            "Train |     1/1    | loss:    0.6203 | fps:    6.9409 | acc:    0.7692   \n",
            "Valid |     1/1    | loss:    0.4642 | fps:    3.7500 | acc:    1.0000   \n",
            "\n",
            "Epoch 4/8\n",
            "----------\n",
            "Train |     1/1    | loss:    0.4899 | fps:    6.8301 | acc:    0.8462   \n",
            "Valid |     1/1    | loss:    0.3971 | fps:    3.7575 | acc:    1.0000   \n",
            "\n",
            "Epoch 5/8\n",
            "----------\n",
            "Train |     1/1    | loss:    0.3685 | fps:    6.6535 | acc:    0.9231   \n",
            "Valid |     1/1    | loss:    0.3399 | fps:    3.6440 | acc:    1.0000   \n",
            "\n",
            "Epoch 6/8\n",
            "----------\n",
            "Train |     1/1    | loss:    0.2539 | fps:    6.6211 | acc:    1.0000   \n",
            "Valid |     1/1    | loss:    0.3238 | fps:    3.6392 | acc:    1.0000   \n",
            "\n",
            "Epoch 7/8\n",
            "----------\n",
            "Train |     1/1    | loss:    0.2629 | fps:    6.7157 | acc:    1.0000   \n",
            "Valid |     1/1    | loss:    0.3124 | fps:    3.6955 | acc:    1.0000   \n",
            "\n",
            "Epoch 8/8\n",
            "----------\n",
            "Train |     1/1    | loss:    0.2449 | fps:    6.7594 | acc:    1.0000   \n",
            "Valid |     1/1    | loss:    0.3018 | fps:    3.6576 | acc:    1.0000   \n"
          ]
        }
      ],
      "source": [
        "writer = SummaryWriter()\n",
        "writer.iteration, writer.interval = 0, 10\n",
        "\n",
        "print('\\n\\nInitial')\n",
        "print('-' * 10)\n",
        "resnet.eval()\n",
        "training.pass_epoch(\n",
        "    resnet, loss_fn, val_loader,\n",
        "    batch_metrics=metrics, show_running=True, device=device,\n",
        "    writer=writer\n",
        ")\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print('\\nEpoch {}/{}'.format(epoch + 1, epochs))\n",
        "    print('-' * 10)\n",
        "\n",
        "    resnet.train()\n",
        "    training.pass_epoch(\n",
        "        resnet, loss_fn, train_loader, optimizer, scheduler,\n",
        "        batch_metrics=metrics, show_running=True, device=device,\n",
        "        writer=writer\n",
        "    )\n",
        "\n",
        "    resnet.eval()\n",
        "    training.pass_epoch(\n",
        "        resnet, loss_fn, val_loader,\n",
        "        batch_metrics=metrics, show_running=True, device=device,\n",
        "        writer=writer\n",
        "    )\n",
        "\n",
        "writer.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#test"
      ],
      "metadata": {
        "id": "oVsh5wKgvEc7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://vcdn-ngoisao.vnecdn.net/2021/10/30/settopjolie-1635526336-6968-1635526893_1200x0.jpg -q -O test1.jpg "
      ],
      "metadata": {
        "id": "kuaE99DvvUY9"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image"
      ],
      "metadata": {
        "id": "_FMVE733viU5"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = mtcnn(Image.open(\"/content/facenet-pytorch/data/test_images/tranbaotri/6.jpg\"), save_path='test1_mt.jpg').unsqueeze(0)\n",
        "test = torch.concat([test, test], dim=0)"
      ],
      "metadata": {
        "id": "x2J8vVM-vXzq"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet.eval()"
      ],
      "metadata": {
        "id": "exAZvedewhbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.argmax(resnet(test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1MkwWw0vsF7",
        "outputId": "41e66b8c-bef2-4dd2-c6cf-accd4aae665f"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3)"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Saving"
      ],
      "metadata": {
        "id": "ph83oFfiEAgL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/facenet-pytorch/checkpoints"
      ],
      "metadata": {
        "id": "unggVgMwD9F7"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ckp_dir = \"/content/facenet-pytorch/checkpoints\"\n",
        "torch.save(resnet.state_dict(), ckp_dir + 'model.pt')"
      ],
      "metadata": {
        "id": "wWadmbF8Eg1D"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#New person"
      ],
      "metadata": {
        "id": "iqPRV4bR1JBJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/facenet-pytorch/data/test_images/tranbaotri"
      ],
      "metadata": {
        "id": "e--SIOMav2Sg"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#....\n"
      ],
      "metadata": {
        "id": "hGf9w1xTDFEw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/thangnch/MiAI_FaceRecog_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjuordGuDP0s",
        "outputId": "e5336030-5a56-44bc-cffa-e2e33c36a05b"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MiAI_FaceRecog_2'...\n",
            "remote: Enumerating objects: 129, done.\u001b[K\n",
            "remote: Counting objects: 100% (15/15), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 129 (delta 3), reused 9 (delta 0), pack-reused 114\u001b[K\n",
            "Receiving objects: 100% (129/129), 2.70 MiB | 6.35 MiB/s, done.\n",
            "Resolving deltas: 100% (35/35), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "from flask import Flask\n",
        "from flask import render_template , request\n",
        "from flask_cors import CORS, cross_origin\n",
        "import torchvision.transforms as tf\n",
        "import argparse\n",
        "import os\n",
        "import sys\n",
        "import math\n",
        "import pickle\n",
        "import align.detect_face\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import cv2\n",
        "import collections\n",
        "from sklearn.svm import SVC\n",
        "import base64\n",
        "\n",
        "FACENET_MODEL_PATH = '/content/facenet-pytorch/checkpoints' + 'model.pt'\n",
        "mtcnn = MTCNN(keep_all=True, post_process=False)\n",
        "#get from config\n",
        "num_classes = 4\n",
        "class_name = ['jolie', 'john', 'badd', 'tri']\n",
        "class_dict = dict([(class_name[i], num_classes[i]) for i in range(num_classes)])\n",
        "\n",
        "def get_face(image):\n",
        "  mtcnn = MTCNN(keep_all=True, post_process=False)\n",
        "  face = mtcnn(image)[0]\n",
        "  image = transforms.Resize((160, 160))((transforms.ToTensor()((Image.fromarray(face.permute(1, 2, 0).numpy().astype(np.uint8))))))\n",
        "  image = Image.fromarray(face.permute(1, 2, 0).numpy().astype(np.uint8))\n",
        "  return image\n",
        "\n",
        "\n",
        "\n",
        "# Load the model\n",
        "print('Loading feature extraction model')\n",
        "facenet = InceptionResnetV1(\n",
        "    classify=True,\n",
        "    pretrained='vggface2',\n",
        "    num_classes=num_classes\n",
        ").to(device)\n",
        "\n",
        "facenet.load_state_dict(torch.load(FACENET_MODEL_PATH))\n",
        "facenet.eval()\n",
        "\n",
        "# Get input and output tensors by POST\n",
        "\n",
        "\n",
        "\n",
        "app = Flask(__name__)\n",
        "CORS(app)\n",
        "\n",
        "\n",
        "\n",
        "@app.route('/')\n",
        "@cross_origin()\n",
        "def index():\n",
        "    return \"OK!\";\n",
        "\n",
        "@app.route('/recog', methods=['POST'])\n",
        "@cross_origin()\n",
        "def upload_img_file():\n",
        "    if request.method == 'POST':\n",
        "        name = \"Unknown\"\n",
        "        og_image = request.form.get('image')\n",
        "        image = get_face(og_image)\n",
        "        image = tf.ToTensor()(image)\n",
        "        logits = facenet(image)\n",
        "        name = class_dict[torch.argmax(logits).item()]\n",
        "\n",
        "\n",
        "        \n",
        "\n",
        "        return name;\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True, host='0.0.0.0',port='8000')\n",
        "\n"
      ],
      "metadata": {
        "id": "v535uUibDdGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "get_face()\n"
      ],
      "metadata": {
        "id": "Pz8ZqI3pGgfm"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}