{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**XLnet vs Bert in text classification**"
      ],
      "metadata": {
        "id": "nqFMtEq5yBdW"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vfwCnC7TcRJ"
      },
      "source": [
        "#packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kZ2rOgGPLrO",
        "outputId": "a9684cfd-3f54-4e81-cc55-633daaf591f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 4.7 MB 5.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 143 kB 73.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 42.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 101 kB 11.7 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q transformers accelerate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7T_gHveKnEDF"
      },
      "source": [
        "#data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-rgVIbOnJEr",
        "outputId": "750809b8-223e-4dd8-edc6-c2be6cbd2aaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1wHt8PsMLsfX5yNSqrt2fSTcb8LEiclcf\n",
            "To: /content/data.zip\n",
            "100% 491k/491k [00:00<00:00, 132MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown --id  1wHt8PsMLsfX5yNSqrt2fSTcb8LEiclcf                                                             "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cR9mn8jRnKfJ",
        "outputId": "98ca9b58-8f58-458c-f241-7986d4162e0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/data.zip\n",
            "  inflating: complaint1700.csv       \n",
            "  inflating: noncomplaint1700.csv    \n",
            "  inflating: test_data.csv           \n"
          ]
        }
      ],
      "source": [
        "!unzip /content/data.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8LAN-f6rnxUU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFC2Ht2xnx1u"
      },
      "outputs": [],
      "source": [
        "pos = pd.read_csv('/content/complaint1700.csv')\n",
        "pos['label'] = 0\n",
        "neg = pd.read_csv('/content/noncomplaint1700.csv')\n",
        "neg['label'] = 1\n",
        "train_df = pd.concat([pos, neg]).reset_index(drop=True)\n",
        "\n",
        "\n",
        "\n",
        "train_df = train_df.loc[:, ['tweet', 'label']]\n",
        "test_df = pd.read_csv('/content/test_data.csv').loc[:, ['tweet']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PEf9tbBSnzgi"
      },
      "outputs": [],
      "source": [
        "def text_preprocessing(text):\n",
        "    \"\"\"\n",
        "    - Remove entity mentions (eg. '@united')\n",
        "    - Correct errors (eg. '&amp;' to '&')\n",
        "    @param    text (str): a string to be processed.\n",
        "    @return   text (Str): the processed string.\n",
        "    \"\"\"\n",
        "    # Remove '@name'\n",
        "    text = re.sub(r'(@.*?)[\\s]', ' ', text)\n",
        "\n",
        "    # Replace '&amp;' with '&'\n",
        "    text = re.sub(r'&amp;', '&', text)\n",
        "\n",
        "    # Remove trailing whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RlF9H_DkpEgD"
      },
      "outputs": [],
      "source": [
        "train_df['tweet'] = train_df['tweet'].apply(text_preprocessing)\n",
        "test_df['tweet'] = test_df['tweet'].apply(text_preprocessing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q66g2n7VpGh7"
      },
      "outputs": [],
      "source": [
        "#train val\n",
        "concat_df = train_df\n",
        "train_df, val_df = train_test_split(concat_df, test_size=0.2, random_state=3)\n",
        "train_df = train_df.reset_index(drop=True)\n",
        "val_df = val_df.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hUK2HnVvpOYu"
      },
      "outputs": [],
      "source": [
        "#vocab \n",
        "\n",
        "class Vocab:\n",
        "    def __init__(self, name=None):\n",
        "        self.name = name\n",
        "        self.word2idx = {\"[PAD]\": 0, \"[SOS]\": 1, \"[EOS]\": 2}\n",
        "        self.idx2word = {1: \"[SOS]\", 0: \"[PAD]\", 2: \"[EOS]\"} #3 special keywords\n",
        "        self.num_words = 3\n",
        "        self.word_counts = {} #SOS, EOS, PAD\n",
        "\n",
        "    def add_sentence(self, sentence):\n",
        "        for word in sentence.split():\n",
        "            self.add_word(word)\n",
        "    def add_word(self, word):\n",
        "        if word in self.word2idx.keys():\n",
        "            self.word_counts[word] += 1\n",
        "\n",
        "        else:\n",
        "            self.word2idx[word] = self.num_words\n",
        "            self.idx2word[self.num_words] = word\n",
        "            self.word_counts[word] = 1 \n",
        "            self.num_words += 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTQMmNugpd7C",
        "outputId": "d5d02361-320f-44ba-b7e1-fc01cce0d371"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "vocab = Vocab()\n",
        "sentences = []\n",
        "sentences.extend(concat_df['tweet'])\n",
        "sentences.extend(test_df['tweet'])\n",
        "for sentence in sentences:\n",
        "  if \"EOS\" in sentence:\n",
        "    print(sentence)\n",
        "    break\n",
        "    vocab.add_sentence(sentence)\n",
        "\n",
        "vocab.num_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "9QtUe4wYpifr",
        "outputId": "58503c79-ed68-4379-9783-3fa2523e4911"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#get the MAXLEN\n",
        "length = {}\n",
        "for sentence in sentences:\n",
        "  if len(sentence.split()) in length:\n",
        "    length[len(sentence.split())] += 1 \n",
        "  else:\n",
        "    length[len(sentence.split())] = 1\n",
        "\n",
        "list_dict = sorted([(i, j) for i, j in length.items()], key=lambda x: x[1], reverse=True)[:10]\n",
        "label = [list_dict[i][0] for i in range(len(list_dict))]\n",
        "fig, ax = plt.subplots(figsize=(15,6))\n",
        "pos = np.arange(10)\n",
        "ax.bar(pos, [i[1] for i in list_dict], width=0.5)\n",
        "ax.set_xticks(pos)\n",
        "ax.set_xticklabels(label)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tVxDlOmnqAJl"
      },
      "outputs": [],
      "source": [
        "MAXLEN = 24"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N3iPFjcjpkT7"
      },
      "outputs": [],
      "source": [
        "# Create a function to tokenize a set of texts\n",
        "def preprocessing_for_pretrained(data, tokenizer):\n",
        "    \"\"\"Perform required preprocessing steps for pretrained BERT.\n",
        "    @param    data (np.array): Array of texts to be processed.\n",
        "    @return   input_ids (torch.Tensor): Tensor of token ids to be fed to a model.\n",
        "    @return   attention_masks (torch.Tensor): Tensor of indices specifying which\n",
        "                  tokens should be attended to by the model.\n",
        "    \"\"\"\n",
        "    # Create empty lists to store outputs\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    # For every sentence...\n",
        "    for sent in data:\n",
        "        token = tokenizer(\n",
        "            text=text_preprocessing(sent),  # Preprocess sentence\n",
        "            max_length=MAXLEN,                  # Max length to truncate/pad\n",
        "            pad_to_max_length=True,         # Pad sentence to max length\n",
        "            # return_tensors='pt',           # Return PyTorch tensor, but we use list for concat later \n",
        "            return_attention_mask=True      # Return attention mask\n",
        "            )\n",
        "        \n",
        "        # Add the outputs to the lists\n",
        "        input_ids.append(token['input_ids'])\n",
        "        attention_masks.append(token['attention_mask'])\n",
        "\n",
        "    # Convert lists to tensors\n",
        "    input_ids = torch.tensor(input_ids)\n",
        "    attention_masks = torch.tensor(attention_masks)\n",
        "\n",
        "    return input_ids, attention_masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BrhYDmCjqKvW"
      },
      "outputs": [],
      "source": [
        "# preprocessing_for_pretrained(val_df, xlnet_tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkOsD8jgjFep"
      },
      "source": [
        "#models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N7BUmgCijEwG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import warnings\n",
        "from tqdm.auto import tqdm\n",
        "from time import sleep\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "from transformers import AutoTokenizer, BertModel, AdamW, AutoModel, BertConfig\n",
        "from accelerate import Accelerator\n",
        "\n",
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xknpcvnNjKJK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18b0756f-d17e-426f-8466-a772e65c5dfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetModel: ['lm_loss.weight', 'lm_loss.bias']\n",
            "- This IS expected if you are initializing XLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "'''xlnet vs bert, M and pretrained R \n",
        "  config is M = untrained R .from_config\n",
        "  pretrained is M = trained R .from_pretrained\n",
        "  model.config -> check the config if u wanna  \n",
        "''' \n",
        "#XLNET, config example \n",
        "# xlnet_config = XLNetConfig()\n",
        "# xlnet = AutoModel.from_config(xlnet_config) from scratch\n",
        "xlnet_tokenizer = AutoTokenizer.from_pretrained('xlnet-base-cased')\n",
        "xlnet = AutoModel.from_pretrained('xlnet-base-cased')\n",
        "#BERT\n",
        "bert_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "bert = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "info: \n",
        "input_ids: tokenize, special <sep> <cls> for xlnet, <cls> for bert\n",
        "attention_mask:\n",
        "token_type: different for pairs, and token type for <cls> in xlnet is 2 \n",
        "\n",
        "'''\n",
        "sentence = \"my name is good boy\"\n",
        "sub = \"you too\"\n",
        "bert_token = tokenizer(sentence, sub, return_tensors='pt')\n",
        "xlnet_token = xlnet_tokenizer(sentence, return_tensors='pt')\n",
        "\n",
        "input_ids, attention_masks = bert_token['input_ids'], bert_token['attention_mask']\n",
        "input_ids, attention_masks = xlnet_token['input_ids'], xlnet_token['attention_mask']\n",
        "# bert(input_ids, attention_masks)['pooler_output'].shape\n",
        "# [xlnet_tokenizer.convert_ids_to_tokens(i) for i in input_ids], input_ids, attention_masks"
      ],
      "metadata": {
        "id": "59QD00VFHBTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xlnet(input_ids, attention_masks)['last_hidden_state'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDxSCjtes3TT",
        "outputId": "905ce863-ee12-47fd-bafb-dfb151a64205"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 7, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Xlnet_classifier(nn.Module):\n",
        "    \"\"\"Bert Model for Classification Tasks.\n",
        "    \"\"\"\n",
        "    def __init__(self, freeze_bert=False):\n",
        "        \"\"\"\n",
        "        @param    bert: a BertModel object\n",
        "        @param    classifier: a torch.nn.Module classifier\n",
        "        @param    freeze_bert (bool): Set `False` to fine-tune the BERT model\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        # Specify hidden size of BERT, hidden size of our classifier, and number of labels\n",
        "        D_in, H, D_out = 768, 50, 2\n",
        "\n",
        "        # Instantiate BERT model\n",
        "        self.xlnet = AutoModel.from_pretrained('xlnet-base-cased')\n",
        "\n",
        "        # Instantiate an one-layer feed-forward classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(D_in, H),\n",
        "            nn.ReLU(),\n",
        "            #nn.Dropout(0.5),\n",
        "            nn.Linear(H, D_out)\n",
        "        )\n",
        "\n",
        "        # Freeze the Xlnet model\n",
        "        if freeze_bert:\n",
        "            for param in self.bert.parameters():\n",
        "                param.requires_grad = False\n",
        "        \n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        \"\"\"\n",
        "        Feed input to BERT and the classifier to compute logits.\n",
        "        @param    input_ids (torch.Tensor): an input tensor with shape (batch_size,\n",
        "                      max_length)\n",
        "        @param    attention_mask (torch.Tensor): a tensor that hold attention mask\n",
        "                      information with shape (batch_size, max_length)\n",
        "        @return   logits (torch.Tensor): an output tensor with shape (batch_size,\n",
        "                      num_labels)\n",
        "        \"\"\"\n",
        "        # Feed input to BERT\n",
        "        outputs = self.xlnet(input_ids=input_ids,\n",
        "                            attention_mask=attention_mask)\n",
        "        \n",
        "        # Extract the last hidden state of the token `[CLS]` for classification task\n",
        "        last_hidden_state_cls = outputs['last_hidden_state'][:, -1, :]\n",
        "\n",
        "        # Feed input to classifier to compute logits\n",
        "        logits = self.classifier(last_hidden_state_cls)\n",
        "\n",
        "        return logits"
      ],
      "metadata": {
        "id": "WKHtPQrRqWH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7tbfkNHikGz4"
      },
      "outputs": [],
      "source": [
        "class Bert_classifier(nn.Module):\n",
        "    \"\"\"Bert Model for Classification Tasks.\n",
        "    \"\"\"\n",
        "    def __init__(self, freeze_bert=False):\n",
        "        \"\"\"\n",
        "        @param    bert: a BertModel object\n",
        "        @param    classifier: a torch.nn.Module classifier\n",
        "        @param    freeze_bert (bool): Set `False` to fine-tune the BERT model\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        # Specify hidden size of BERT, hidden size of our classifier, and number of labels\n",
        "        D_in, H, D_out = 768, 50, 2\n",
        "\n",
        "        # Instantiate BERT model\n",
        "        self.bert = AutoModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "        # Instantiate an one-layer feed-forward classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(D_in, H),\n",
        "            nn.ReLU(),\n",
        "            #nn.Dropout(0.5),\n",
        "            nn.Linear(H, D_out)\n",
        "        )\n",
        "\n",
        "        # Freeze the BERT model\n",
        "        if freeze_bert:\n",
        "            for param in self.bert.parameters():\n",
        "                param.requires_grad = False\n",
        "        \n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        \"\"\"\n",
        "        Feed input to BERT and the classifier to compute logits.\n",
        "        @param    input_ids (torch.Tensor): an input tensor with shape (batch_size,\n",
        "                      max_length)\n",
        "        @param    attention_mask (torch.Tensor): a tensor that hold attention mask\n",
        "                      information with shape (batch_size, max_length)\n",
        "        @return   logits (torch.Tensor): an output tensor with shape (batch_size,\n",
        "                      num_labels)\n",
        "        \"\"\"\n",
        "        # Feed input to BERT\n",
        "        outputs = self.bert(input_ids=input_ids,\n",
        "                            attention_mask=attention_mask)\n",
        "        \n",
        "        # Extract the last hidden state of the token `[CLS]` for classification task\n",
        "        last_hidden_state_cls = outputs['pooler_output']\n",
        "\n",
        "        # Feed input to classifier to compute logits\n",
        "        logits = self.classifier(last_hidden_state_cls)\n",
        "\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#train"
      ],
      "metadata": {
        "id": "9PpZjYUsE3rt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader"
      ],
      "metadata": {
        "id": "JR-nLH0hFG9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train_df['tweet']\n",
        "X_val = val_df['tweet']\n",
        "X_test = test_df['tweet']\n",
        "MAX_LEN = 24"
      ],
      "metadata": {
        "id": "cA9kES3eFGyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = xlnet_tokenizer"
      ],
      "metadata": {
        "id": "wT6U3O_ftQZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WnYOP22dnsyh"
      },
      "outputs": [],
      "source": [
        "X_train_input, X_train_attention = preprocessing_for_pretrained(X_train, tokenizer)\n",
        "X_val_input, X_val_attention = preprocessing_for_pretrained(X_val, tokenizer) \n",
        "X_test_input, X_test_attention = preprocessing_for_pretrained(X_test, tokenizer)\n",
        "y_train = torch.tensor(train_df['label'].values, dtype=torch.long)\n",
        "y_val = torch.tensor(val_df['label'].values, dtype=torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert other data types to torch.Tensor\n",
        "train_labels = torch.tensor(y_train)\n",
        "val_labels = torch.tensor(y_val)\n",
        "epochs = 10\n",
        "# For fine-tuning BERT, the authors recommend a batch size of 16 or 32.\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoader for our training set\n",
        "train_data = TensorDataset(X_train_input, X_train_attention, y_train)\n",
        "train_dataloader = DataLoader(train_data,  batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Create the DataLoader for our validation set\n",
        "val_data = TensorDataset(X_val_input, X_val_attention, y_val)\n",
        "val_dataloader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
        "model = Xlnet_classifier()\n",
        "optimizer = AdamW(model.parameters(), lr=5e-6)\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                                num_warmup_steps=0, # Default value\n",
        "                                                num_training_steps=total_steps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0rgj21fFBSA",
        "outputId": "dc6e8667-1161-4dd4-b640-cafd19936fc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetModel: ['lm_loss.weight', 'lm_loss.bias']\n",
            "- This IS expected if you are initializing XLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accelerator = Accelerator()\n",
        "model, optimizer, train_dataloader, val_dataloader = accelerator.prepare(\n",
        "    model, optimizer, train_dataloader, val_dataloader\n",
        ")\n",
        "accelerator.device\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "Vv81z_9DFSKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import time\n",
        "\n",
        "# Specify loss function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def set_seed(seed_value=42):\n",
        "    \"\"\"Set seed for reproducibility.\n",
        "    \"\"\"\n",
        "    random.seed(seed_value)\n",
        "    np.random.seed(seed_value)\n",
        "    torch.manual_seed(seed_value)\n",
        "    torch.cuda.manual_seed_all(seed_value)\n",
        "\n",
        "def train(model, train_dataloader, val_dataloader=None, epochs=4, evaluation=False):\n",
        "    \"\"\"Train the BertClassifier model.\n",
        "    \"\"\"\n",
        "    # Start training loop\n",
        "    print(\"Start training...\\n\")\n",
        "    run = tqdm(range(total_steps))\n",
        "    for epoch_i in range(epochs):\n",
        "        # =======================================\n",
        "        #               Training\n",
        "        # =======================================\n",
        "        # Print the header of the result table\n",
        "        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n",
        "        print(\"-\"*70)\n",
        "\n",
        "        # Measure the elapsed time of each epoch\n",
        "        t0_epoch, t0_batch = time.time(), time.time()\n",
        "\n",
        "        # Reset tracking variables at the beginning of each epoch\n",
        "        total_loss, batch_loss, batch_counts = 0, 0, 0\n",
        "\n",
        "        # Put the model into the training mode\n",
        "        model.train()\n",
        "\n",
        "        # For each batch of training data...\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            batch_counts +=1\n",
        "            # Load batch to GPU\n",
        "            b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "            # Zero out any previously calculated gradients\n",
        "            optimizer.zero_grad()\n",
        "            # print(b_input_ids.shape, b_attn_mask.shape)\n",
        "            # Perform a forward pass. This will return logits.\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "            # Compute loss and accumulate the loss values\n",
        "            loss = loss_fn(logits, b_labels)\n",
        "            batch_loss += loss.item()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Perform a backward pass to calculate gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            # Update parameters and the learning rate\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            run.update(1)\n",
        "\n",
        "\n",
        "            # Print the loss values and time elapsed for every 20 batches\n",
        "            if (step % 20 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n",
        "                # Calculate time elapsed for 20 batches\n",
        "                time_elapsed = time.time() - t0_batch\n",
        "\n",
        "                # Print training results\n",
        "                print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n",
        "\n",
        "                # Reset batch tracking variables\n",
        "                batch_loss, batch_counts = 0, 0\n",
        "                t0_batch = time.time()\n",
        "\n",
        "        # Calculate the average loss over the entire training data\n",
        "        avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "        print(\"-\"*70)\n",
        "        # =======================================\n",
        "        #               Evaluation\n",
        "        # =======================================\n",
        "        if evaluation == True:\n",
        "            with torch.no_grad():\n",
        "              model.eval()\n",
        "              # After the completion of each training epoch, measure the model's performance\n",
        "              # on our validation set.\n",
        "              val_loss, val_accuracy = evaluate(model, val_dataloader)\n",
        "\n",
        "              # Print performance over the entire training data\n",
        "              time_elapsed = time.time() - t0_epoch\n",
        "              \n",
        "              print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n",
        "              print(\"-\"*70)\n",
        "        print(\"\\n\")\n",
        "    \n",
        "    print(\"Training complete!\")\n",
        "\n",
        "\n",
        "def evaluate(model, val_dataloader):\n",
        "    \"\"\"After the completion of each training epoch, measure the model's performance\n",
        "    on our validation set.\n",
        "    \"\"\"\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
        "    # the test time.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    val_accuracy = []\n",
        "    val_loss = []\n",
        "\n",
        "    # For each batch in our validation set...\n",
        "    for batch in val_dataloader:\n",
        "        # Load batch to GPU\n",
        "        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        # Compute logits\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = loss_fn(logits, b_labels)\n",
        "        val_loss.append(loss.item())\n",
        "\n",
        "        # Get the predictions\n",
        "        preds = torch.argmax(logits, dim=1).flatten()\n",
        "        prob = nn.functional.softmax(logits, dim=1)\n",
        "  \n",
        "\n",
        "        # Calculate the accuracy rate\n",
        "        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
        "        val_accuracy.append(accuracy)\n",
        "\n",
        "    # Compute the average accuracy and loss over the validation set.\n",
        "    val_loss = np.mean(val_loss)\n",
        "    val_accuracy = np.mean(val_accuracy)\n",
        "\n",
        "    return val_loss, val_accuracy"
      ],
      "metadata": {
        "id": "uImYGKZ3GdOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(3)\n",
        "train(model, train_dataloader, val_dataloader, epochs=15, evaluation=True)"
      ],
      "metadata": {
        "id": "nGxzzge-Fg3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#evaluation"
      ],
      "metadata": {
        "id": "E5tDKMPCuskA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def predict(model, test_dataloader):\n",
        "    \"\"\"Perform a forward pass on the trained BERT model to predict probabilities\n",
        "    on the test set.\n",
        "    \"\"\"\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
        "    # the test time.\n",
        "    model.eval()\n",
        "\n",
        "    all_logits = []\n",
        "\n",
        "    # For each batch in our test set...\n",
        "    for batch in test_dataloader:\n",
        "        # Load batch to GPU\n",
        "        b_input_ids, b_attn_mask = tuple(t.to(device) for t in batch)[:2]\n",
        "\n",
        "        # Compute logits\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "        all_logits.append(logits)\n",
        "    \n",
        "    # Concatenate logits from each batch\n",
        "    all_logits = torch.cat(all_logits, dim=0)\n",
        "\n",
        "    # Apply softmax to calculate probabilities\n",
        "    probs = F.softmax(all_logits, dim=1).cpu().numpy()\n",
        "\n",
        "    return probs"
      ],
      "metadata": {
        "id": "01jTagJLFip8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_roc(probs, y_true):\n",
        "    \"\"\"\n",
        "    - Print AUC and accuracy on the test set\n",
        "    - Plot ROC\n",
        "    @params    probs (np.array): an array of predicted probabilities with shape (len(y_true), 2)\n",
        "    @params    y_true (np.array): an array of the true values with shape (len(y_true),)\n",
        "    \"\"\"\n",
        "    preds = probs[:, 1]\n",
        "    fpr, tpr, threshold = roc_curve(y_true, preds)\n",
        "    print(threshold)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    print(f'AUC: {roc_auc:.4f}')\n",
        "       \n",
        "    # # Get accuracy over the test set\n",
        "    # y_pred = np.where(preds >= 0.5, 1, 0)\n",
        "    # accuracy = accuracy_score(y_true, y_pred)\n",
        "    # print(f'Accuracy: {accuracy*100:.2f}%')\n",
        "    \n",
        "    # Plot ROC AUC\n",
        "    plt.title('Receiver Operating Characteristic')\n",
        "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "    plt.legend(loc = 'lower right')\n",
        "    plt.plot([0, 1], [0, 1],'r--')\n",
        "    plt.xlim([0, 1])\n",
        "    plt.ylim([0, 1])\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Ym7Oc_5YwkQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probs = predict(model, val_dataloader)\n",
        "probs.shape #prob for 2 classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2H2Wsu1axOM8",
        "outputId": "26ce0f4f-c5a3-4dbf-b896-838a4fcfc013"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(680, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_roc(probs, y_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CIc-zk8PxdBM",
        "outputId": "2b1109c2-8d7a-441f-c1f6-880143461949"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.99409628e+00 9.94096279e-01 9.92628694e-01 9.92562473e-01\n",
            " 9.86936510e-01 9.86666858e-01 9.83056486e-01 9.82909560e-01\n",
            " 9.78563249e-01 9.78093266e-01 9.76193130e-01 9.75632370e-01\n",
            " 9.60691988e-01 9.59332228e-01 9.58157241e-01 9.58072603e-01\n",
            " 9.55093920e-01 9.54745114e-01 9.54149842e-01 9.46132123e-01\n",
            " 9.44670618e-01 9.40278172e-01 9.40025210e-01 9.36607718e-01\n",
            " 9.33917224e-01 9.30116355e-01 9.29498851e-01 9.23274517e-01\n",
            " 9.22860384e-01 9.15024638e-01 9.13902521e-01 9.13099051e-01\n",
            " 9.10724938e-01 9.03326809e-01 9.03264940e-01 8.97718549e-01\n",
            " 8.97458494e-01 8.89981151e-01 8.89216721e-01 8.89095485e-01\n",
            " 8.88481438e-01 8.74667048e-01 8.71894598e-01 8.69242489e-01\n",
            " 8.67363513e-01 8.67310286e-01 8.66024613e-01 8.62882793e-01\n",
            " 8.59091818e-01 8.38558257e-01 8.35290372e-01 8.34790349e-01\n",
            " 8.34255874e-01 8.34236443e-01 8.29466045e-01 8.23168278e-01\n",
            " 8.18165720e-01 8.15200925e-01 8.12802851e-01 8.10909092e-01\n",
            " 8.05890441e-01 7.99788952e-01 7.98482776e-01 7.97590137e-01\n",
            " 7.86563456e-01 7.83838689e-01 7.79747784e-01 6.74632370e-01\n",
            " 6.74564123e-01 6.73153043e-01 6.67758644e-01 6.62994802e-01\n",
            " 6.60784841e-01 6.56526148e-01 6.55397296e-01 6.55155957e-01\n",
            " 6.43095791e-01 6.41425729e-01 6.36182964e-01 6.19215429e-01\n",
            " 6.18988514e-01 6.08732164e-01 6.01227701e-01 5.96131086e-01\n",
            " 5.94123781e-01 5.86098313e-01 5.84385514e-01 5.77699840e-01\n",
            " 5.66142619e-01 5.65051734e-01 5.62043130e-01 5.55400133e-01\n",
            " 5.31667769e-01 5.23960292e-01 5.11362135e-01 5.07845581e-01\n",
            " 5.05658865e-01 4.91340458e-01 4.90443468e-01 4.83488292e-01\n",
            " 4.83047724e-01 4.80688721e-01 4.65800852e-01 4.64728415e-01\n",
            " 4.62852508e-01 4.61123914e-01 4.43617612e-01 4.30562764e-01\n",
            " 4.27408338e-01 4.16857719e-01 4.04201537e-01 4.03777331e-01\n",
            " 3.82142991e-01 3.80541623e-01 3.77073020e-01 3.75716954e-01\n",
            " 3.65313381e-01 3.61049056e-01 3.53288949e-01 3.51937234e-01\n",
            " 3.45050782e-01 3.36911470e-01 3.29054177e-01 3.23158562e-01\n",
            " 2.87913412e-01 2.78193921e-01 2.66469479e-01 2.66082108e-01\n",
            " 2.45707095e-01 2.42512405e-01 2.42079824e-01 2.32625037e-01\n",
            " 2.26599008e-01 2.25903928e-01 2.25245491e-01 2.15959325e-01\n",
            " 2.13637426e-01 2.10590392e-01 2.06788942e-01 2.00630710e-01\n",
            " 1.93806157e-01 1.91355780e-01 1.88094065e-01 1.85688570e-01\n",
            " 1.72814474e-01 1.67618334e-01 1.65181801e-01 1.63599938e-01\n",
            " 1.56335801e-01 1.54712155e-01 1.54236317e-01 1.50131747e-01\n",
            " 1.49890527e-01 1.44598737e-01 1.29682600e-01 1.27145112e-01\n",
            " 1.23626314e-01 1.23588443e-01 1.15717515e-01 1.15442105e-01\n",
            " 1.12922214e-01 1.10714063e-01 1.03518769e-01 1.03061885e-01\n",
            " 9.87201110e-02 9.84692499e-02 9.65817794e-02 9.65556502e-02\n",
            " 9.46562886e-02 8.90871808e-02 8.58813822e-02 8.06073099e-02\n",
            " 7.67074376e-02 7.31341168e-02 6.17318265e-02 6.08302392e-02\n",
            " 6.02533147e-02 5.75278886e-02 5.42248189e-02 5.37568480e-02\n",
            " 5.27390316e-02 5.21711260e-02 4.53042351e-02 4.47231457e-02\n",
            " 4.36672978e-02 4.26769108e-02 4.14039232e-02 4.05974388e-02\n",
            " 3.96692045e-02 3.86247635e-02 3.54753844e-02 3.52790244e-02\n",
            " 3.25935408e-02 3.10646929e-02 2.48389728e-02 2.41624005e-02\n",
            " 2.38845982e-02 2.37332769e-02 2.09844112e-02 2.02659536e-02\n",
            " 1.97957531e-02 1.93573982e-02 1.81673057e-02 1.79280527e-02\n",
            " 1.29520306e-02 1.27955843e-02 1.09480927e-02 1.08097168e-02\n",
            " 7.94800371e-03 7.60274939e-03 7.53256911e-03 7.46603357e-03\n",
            " 3.45714740e-03 3.34441336e-03 1.14400894e-03]\n",
            "AUC: 0.8462\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vP6Ue3cQxmWm"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "NLU_xlnetvsbert.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}