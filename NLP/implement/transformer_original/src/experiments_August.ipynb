{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Implementation of transformer, - testing on the English-French dataset and Movielines**\n",
        "- Use d2l tutorial and my implementation for comparision\n",
        "- Drive mnt: mount drive and get data, set up vocab\n",
        "- packages: Install dependencies\n",
        "- D2l: use d2l packages & my own seq2seq, guides included \n",
        "- Use pretrained tokenizers for Movielines and self-erected Vocab for the Eng~Fre"
      ],
      "metadata": {
        "id": "COe_WlPGFmZL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSUUgfIrX18z"
      },
      "source": [
        "#D2l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_VnZ1IuX4Yy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdf3b7b0-d016-4be6-fedf-0884f2280734"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 92 kB 1.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 120 kB 19.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 69.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 82 kB 585 kB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q d2l==1.0.0-alpha0 matplotlib_inline #d2l packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-f0UW4XdzL7"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn\n",
        "from d2l import torch as d2l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6FUv8SfQeUCS"
      },
      "outputs": [],
      "source": [
        "#d2l PositionwiseFFN and AddNorm\n",
        "class PositionWiseFFN(nn.Module):\n",
        "    \"\"\"Positionwise feed-forward network.\"\"\"\n",
        "    def __init__(self, ffn_num_hiddens, ffn_num_outputs):\n",
        "        super().__init__()\n",
        "        self.dense1 = nn.LazyLinear(ffn_num_hiddens)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dense2 = nn.LazyLinear(ffn_num_outputs)\n",
        "\n",
        "    def forward(self, X):\n",
        "        return self.dense2(self.relu(self.dense1(X)))\n",
        "class AddNorm(nn.Module):\n",
        "    \"\"\"Residual connection followed by layer normalization.\"\"\"\n",
        "    def __init__(self, norm_shape, dropout):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.ln = nn.LayerNorm(norm_shape)\n",
        "\n",
        "    def forward(self, X, Y):\n",
        "        return self.ln(self.dropout(Y) + X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uPCqnZ2pYamy"
      },
      "outputs": [],
      "source": [
        "#D2l encoder\n",
        "class TransformerEncoderBlock(nn.Module):\n",
        "    \"\"\"Transformer encoder block.\"\"\"\n",
        "    def __init__(self, num_hiddens, ffn_num_hiddens, num_heads, dropout,\n",
        "                 use_bias=False):\n",
        "        super().__init__()\n",
        "        self.attention = d2l.MultiHeadAttention(num_hiddens, num_heads,\n",
        "                                                dropout, use_bias)\n",
        "        self.addnorm1 = AddNorm(num_hiddens, dropout)\n",
        "        self.ffn = PositionWiseFFN(ffn_num_hiddens, num_hiddens)\n",
        "        self.addnorm2 = AddNorm(num_hiddens, dropout)\n",
        "\n",
        "    def forward(self, X, valid_lens):\n",
        "        Y = self.addnorm1(X, self.attention(X, X, X, valid_lens))\n",
        "        return self.addnorm2(Y, self.ffn(Y))\n",
        "class TransformerEncoder(nn.Module):\n",
        "    \"\"\"Transformer encoder.\"\"\"\n",
        "    def __init__(self, vocab_size, num_hiddens, ffn_num_hiddens,\n",
        "                 num_heads, num_blks, dropout, use_bias=False):\n",
        "        super().__init__()\n",
        "        self.num_hiddens = num_hiddens\n",
        "        self.embedding = nn.Embedding(vocab_size, num_hiddens)\n",
        "        self.pos_encoding = d2l.PositionalEncoding(num_hiddens, dropout)\n",
        "        self.blks = nn.Sequential()\n",
        "        for i in range(num_blks):\n",
        "            self.blks.add_module(\"block\"+str(i), TransformerEncoderBlock(\n",
        "                num_hiddens, ffn_num_hiddens, num_heads, dropout, use_bias))\n",
        "\n",
        "    def forward(self, X):\n",
        "        valid_lens = torch.tensor(X.shape[1], dtype=torch.long).repeat(X.shape[0])\n",
        "        # print(\"valid\", valid_lens.shape)\n",
        "        # Since positional encoding values are between -1 and 1, the embedding\n",
        "        # values are multiplied by the square root of the embedding dimension\n",
        "        # to rescale before they are summed up\n",
        "        X = self.pos_encoding(self.embedding(X))\n",
        "        self.attention_weights = [None] * len(self.blks)\n",
        "        for i, blk in enumerate(self.blks):\n",
        "            X = blk(X, valid_lens)\n",
        "            self.attention_weights[\n",
        "                i] = blk.attention.attention.attention_weights\n",
        "        return X, valid_lens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cxV-Q-GmeAgi"
      },
      "outputs": [],
      "source": [
        "#D2l Decoder\n",
        "class TransformerDecoderBlock(nn.Module):\n",
        "    # The i-th block in the transformer decoder\n",
        "    def __init__(self, num_hiddens, ffn_num_hiddens, num_heads, dropout, i):\n",
        "        super().__init__()\n",
        "        self.i = i\n",
        "        self.attention1 = d2l.MultiHeadAttention(num_hiddens, num_heads,\n",
        "                                                 dropout)\n",
        "        self.addnorm1 = AddNorm(num_hiddens, dropout)\n",
        "        self.attention2 = d2l.MultiHeadAttention(num_hiddens, num_heads,\n",
        "                                                 dropout)\n",
        "        self.addnorm2 = AddNorm(num_hiddens, dropout)\n",
        "        self.ffn = PositionWiseFFN(ffn_num_hiddens, num_hiddens)\n",
        "        self.addnorm3 = AddNorm(num_hiddens, dropout)\n",
        "\n",
        "    def forward(self, X, state):\n",
        "        enc_outputs, enc_valid_lens = state[0], state[1]\n",
        "        # During training, all the tokens of any output sequence are processed\n",
        "        # at the same time, so state[2][self.i] is None as initialized. When\n",
        "        # decoding any output sequence token by token during prediction,\n",
        "        # state[2][self.i] contains representations of the decoded output at\n",
        "        # the i-th block up to the current time step\n",
        "        if state[2][self.i] is None:\n",
        "            key_values = X\n",
        "        else:\n",
        "            key_values = torch.cat((state[2][self.i], X), dim=1)\n",
        "        state[2][self.i] = key_values\n",
        "        if self.training:\n",
        "            batch_size, num_steps, _ = X.shape\n",
        "            # Shape of dec_valid_lens: (batch_size, num_steps), where every\n",
        "            # row is [1, 2, ..., num_steps]\n",
        "            dec_valid_lens = torch.arange(\n",
        "                1, num_steps + 1, device=X.device).repeat(batch_size, 1)\n",
        "        else:\n",
        "            dec_valid_lens = None\n",
        "        # Self-attention\n",
        "        X2 = self.attention1(X, key_values, key_values, dec_valid_lens)\n",
        "        Y = self.addnorm1(X, X2)\n",
        "        # Encoder-decoder attention. Shape of enc_outputs:\n",
        "        # (batch_size, num_steps, num_hiddens)\n",
        "        Y2 = self.attention2(Y, enc_outputs, enc_outputs, enc_valid_lens)\n",
        "        Z = self.addnorm2(Y, Y2)\n",
        "        return self.addnorm3(Z, self.ffn(Z)), state\n",
        "\n",
        "class TransformerDecoder(nn.Module):\n",
        "    def __init__(self, vocab_size, num_hiddens, ffn_num_hiddens, num_heads,\n",
        "                 num_blks, dropout):\n",
        "        super().__init__()\n",
        "        self.num_hiddens = num_hiddens\n",
        "        self.num_blks = num_blks\n",
        "        self.embedding = nn.Embedding(vocab_size, num_hiddens)\n",
        "        self.pos_encoding = d2l.PositionalEncoding(num_hiddens, dropout)\n",
        "        self.blks = nn.Sequential()\n",
        "        for i in range(num_blks):\n",
        "            self.blks.add_module(\"block\"+str(i), TransformerDecoderBlock(\n",
        "                num_hiddens, ffn_num_hiddens, num_heads, dropout, i))\n",
        "        self.dense = nn.LazyLinear(vocab_size)\n",
        "\n",
        "    def init_state(self, enc_outputs, enc_valid_lens):\n",
        "        return [enc_outputs, enc_valid_lens, [None] * self.num_blks]\n",
        "\n",
        "    def forward(self, X, state):\n",
        "        X = self.pos_encoding(self.embedding(X))\n",
        "        self._attention_weights = [[None] * len(self.blks) for _ in range (2)]\n",
        "        for i, blk in enumerate(self.blks):\n",
        "            X, state = blk(X, state)\n",
        "            # Decoder self-attention weights\n",
        "            self._attention_weights[0][\n",
        "                i] = blk.attention1.attention.attention_weights\n",
        "            # Encoder-decoder attention weights\n",
        "            self._attention_weights[1][\n",
        "                i] = blk.attention2.attention.attention_weights\n",
        "        return self.dense(X), state\n",
        "\n",
        "    @property\n",
        "    def attention_weights(self):\n",
        "        return self._attention_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iPhUb2Ly0e8o"
      },
      "outputs": [],
      "source": [
        "#Seq2Seq for aggregating encoder and decoder\n",
        "class Seq2Seq(nn.Module):\n",
        "    #aggregation OOP\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        '''\n",
        "        output when testing: '<sos>'\n",
        "        '''\n",
        "        x, valid = self.encoder(x)\n",
        "        #encoder: b x n x d\n",
        "        state = self.decoder.init_state(x, valid)\n",
        "        #decoder:\n",
        "        outputs, state = self.decoder(y, state)\n",
        "        return outputs, state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joRT2LuJef1l",
        "outputId": "36175d93-7cc7-4e6e-e2ac-481578a61668"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
            "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 15, 24])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "#test d2l modules \n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "src, tgt = torch.ones(16, 15, dtype=torch.long).to(device), torch.zeros(16, 13, dtype=torch.long).to(device)\n",
        "valid_lens = torch.ones(128)\n",
        "encoder = TransformerEncoder(200, 24, 48, 8, 2, 0.5).to(device)\n",
        "decoder = TransformerDecoder(200, 24, 48, 8, 2, 0.5).to(device)\n",
        "encoder_output = encoder(src)\n",
        "encoder_output[0].shape\n",
        "#modify the torch.py, add .to(X.device) to run tutorials"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXfPkA4LcZuA",
        "outputId": "500484d9-5766-466e-c239-beeaf9b721e1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 13, 200])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "#seq2seq d2l\n",
        "seq2seq = Seq2Seq(encoder, decoder)\n",
        "seq2seq(src, tgt)[0].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## my model"
      ],
      "metadata": {
        "id": "wOkAp43LWjNH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%env dir=/content/deep-learning/NLP/implement/temp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlhJLf-5Nua_",
        "outputId": "73c040b7-9dc5-4067-ce74-0421fc7d61a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: dir=/content/deep-learning/NLP/implement/temp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "coXQzTyA0OV1"
      },
      "outputs": [],
      "source": [
        "#Dataset and train, validation script \n",
        "import sys\n",
        "import time\n",
        "import random\n",
        "from copy import deepcopy\n",
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "PATH = os.environ['dir']\n",
        "sys.path.append(PATH + \"/src\")\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pytorch_lightning as pl\n",
        "import wandb\n",
        "import hydra\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, LearningRateMonitor\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "from transformers import AutoTokenizer\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "- pl_module\n",
        "- simple torch script for debug\n",
        "''' \n",
        "train_loss = []\n",
        "val_loss = []\n",
        "\n",
        "#dataset\n",
        "class ChatDataset(Dataset):\n",
        "    def __init__(self, data, batch=32, max_length=10):\n",
        "        super().__init__()\n",
        "        self.data = data\n",
        "        self.max_length = max_length\n",
        "        self.batch = batch\n",
        "    def __getitem__(self, idx):\n",
        "        src, tgt = self.data.iloc[idx, :]\n",
        "\n",
        "        src = '[BOS] ' + src + ' [EOS]'\n",
        "        tgt = '[BOS] ' + tgt + ' [EOS]'      \n",
        "        #get the tensor word:\n",
        "        #drop the [CLS] token and [SEP]\n",
        "        #current tokenizer, MAX_LEN + 2 -> drop CLS and SEP token later ? ``\n",
        "        while len(engVocab.tokenize(src)) < self.max_length + 2:\n",
        "            src += ' [PAD]'\n",
        "        while len(frVocab.tokenize(tgt)) < self.max_length + 2:\n",
        "            tgt += ' [PAD]'\n",
        "        src_token = torch.tensor(engVocab.tokenize(src), dtype=torch.long)\n",
        "        tgt_token = torch.tensor(frVocab.tokenize(tgt), dtype=torch.long)\n",
        "\n",
        "        if len(src_token) > self.max_length:\n",
        "            src_token = src_token[:self.max_length]\n",
        "        if len(tgt_token) > self.max_length:\n",
        "            tgt_token = tgt_token[:self.max_length]\n",
        "        src_token, tgt_token = src_token, tgt_token   \n",
        "       \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        return src_token, tgt_token\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "class ChatMachine(pl.LightningModule):\n",
        "    '''\n",
        "    lightning module for dataloader, training and testing\n",
        "    '''\n",
        "    def __init__(self, lr, mode='teacher_forcing'):\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder(vocab=VOCAB_SIZE, n_seq=MAX_LEN, d_model=512, d_ff=2048, h=8, N=6, p_drop=0.1, label_smoothing=None)\n",
        "        self.decoder = Decoder(vocab=VOCAB_SIZE, n_seq=MAX_LEN-1, d_model=512, d_ff=2048, h=8, N=6, p_drop=0.1, label_smoothing=None)\n",
        "        self.model = Seq2Seq(self.encoder, self.decoder)\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        src, tgt = batch\n",
        "        decoder_input, decoder_output = deepcopy(tgt[:, :-1]), deepcopy(tgt[:, 1:])\n",
        "        pred = self.model(src, decoder_input)[0]\n",
        "\n",
        "        #teacher forcing a.k.a use default ground truth (use current word -> next word) \n",
        "        if self.hparams.mode == \"teacher_forcing\":\n",
        "            loss = MaskedNLL(pred.reshape(-1, pred.shape[-1]), decoder_output.reshape(-1))\n",
        "            pred_tokens = torch.argmax(pred, dim=-1)\n",
        "            self.log(\"train loss\", loss)\n",
        "            return loss\n",
        "        #uniform random sampling, iterate through the n_seq of target\n",
        "        else:\n",
        "            pred_tokens = torch.argmax(pred, dim=-1)\n",
        "            for i in range(tgt[:, :-1].shape[1]):\n",
        "                p = random.uniform(0, 1)\n",
        "                if p > 0.69:\n",
        "                    decoder_input[:, i] = pred_tokens[:, i]\n",
        "            pred = self.model(src, decoder_input)[0]\n",
        "            loss = MaskedNLL(pred.reshape(-1, pred.shape[-1]), decoder_output.reshape(-1))\n",
        "            pred_tokens = torch.argmax(pred, dim=-1)\n",
        "            self.log(\"train loss\", loss)\n",
        "            return loss\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.hparams.lr)\n",
        "        return {'optimizer': optimizer}\n",
        "\n",
        "\n",
        "def train(train_dataloader, val_dataloader, model, mode='teacher_forcing', device = 'cuda' if torch.cuda.is_available() else 'cpu', lr=1e-3):\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "    for i in range(10):\n",
        "        trainloss = 0\n",
        "        valloss = 0\n",
        "        for src, tgt in train_dataloader:\n",
        "            # start = time.time()\n",
        "            optimizer.zero_grad()\n",
        "            src, tgt = src.to(device), tgt.to(device)\n",
        "            decoder_input, decoder_output = deepcopy(tgt[:, :-1]), deepcopy(tgt[:, 1:])\n",
        "            pred = model(src, decoder_input)[0]\n",
        "            if mode == \"teacher_forcing\":\n",
        "                loss = MaskedNLL(pred.reshape(-1, pred.shape[-1]), decoder_output.reshape(-1))\n",
        "                pred_tokens = torch.argmax(pred, dim=-1)\n",
        "            #uniform random sampling, iterate through the n_seq of target\n",
        "            else:\n",
        "                pred_tokens = torch.argmax(pred, dim=-1)\n",
        "                for i in range(tgt[:, :-1].shape[1]):\n",
        "                    p = random.uniform(0, 1)\n",
        "                    if p > 0.69:\n",
        "                        decoder_input[:, i] = pred_tokens[:, i]\n",
        "                pred = model(src, decoder_input)[0]\n",
        "                loss = MaskedNLL(pred.reshape(-1, pred.shape[-1]), decoder_output.reshape(-1))\n",
        "                pred_tokens = torch.argmax(pred, dim=-1)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            trainloss += loss.item()\n",
        "            # print(\"passed\", time.time() - start)\n",
        "            \n",
        "            # if len(train_loss) % 50 == 0:\n",
        "        \n",
        "        with torch.no_grad():\n",
        "          for src, tgt in val_dataloader:\n",
        "            src, tgt = src.to(device), tgt.to(device)\n",
        "            decoder_input, decoder_output = deepcopy(tgt[:, :-1]), deepcopy(tgt[:, 1:])\n",
        "            pred = model(src, decoder_input)[0]\n",
        "            loss = MaskedNLL(pred.reshape(-1, pred.shape[-1]), decoder_output.reshape(-1))\n",
        "            valloss += loss.item()\n",
        "          val_loss.append(valloss)\n",
        "          train_loss.append(trainloss)\n",
        "          print(f'{i}:', trainloss, valloss)\n",
        "\n",
        "\n",
        "        \n",
        "\n",
        "                    \n",
        "                \n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5V0_5oxdwKu"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pytorch_lightning as pl\n",
        "import wandb\n",
        "import hydra\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, LearningRateMonitor\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "from transformers import AutoTokenizer\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import sys\n",
        "PATH = os.environ['dir']\n",
        "sys.path.append(PATH + \"/src\")\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "from utils import MaskedNLL\n",
        "MAX_LEN = 15\n",
        "dataset = ChatDataset(data)\n",
        "train_data, val_data = train_test_split(data, test_size=0.3)\n",
        "train_dataset = ChatDataset(train_data, max_length=MAX_LEN)\n",
        "val_dataset = ChatDataset(val_data, max_length=MAX_LEN)\n",
        "src_token, tgt_token = train_dataset[0]\n",
        "# train_dataset, val_dataset = train_test_split(dataset, test_size=0.3)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True, drop_last=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=128, shuffle=True, drop_last=True)\n",
        "src, tgt = iter(train_dataloader).next()\n",
        "# # src, tgt\n",
        "num_hiddens, num_blks, dropout = 256, 2, 0.2\n",
        "ffn_num_hiddens, num_heads = 64, 4\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#if we use the d2l modules\n",
        "# encoder = TransformerEncoder(\n",
        "#     engVocab.num_words, num_hiddens, ffn_num_hiddens, num_heads,\n",
        "#     num_blks, dropout)\n",
        "# decoder = TransformerDecoder(\n",
        "#     frVocab.num_words, num_hiddens, ffn_num_hiddens, num_heads,\n",
        "#     num_blks, dropout)\n",
        "# seq2seq = Seq2Seq(encoder, decoder)"
      ],
      "metadata": {
        "id": "kcZXN7nz7KVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#if use my model, run it \n",
        "from models.modules import Seq2Seq, Encoder, Decoder\n",
        "encoder = Encoder(vocab=engVocab.num_words, n_seq=MAX_LEN, d_model=256, d_ff=64, h=4, N=2, p_drop=0.1, label_smoothing=None)\n",
        "decoder = Decoder(vocab=frVocab.num_words, n_seq=MAX_LEN-1, d_model=256, d_ff=64, h=4, N=2, p_drop=0.1, label_smoothing=None)\n",
        "seq2seq = Seq2Seq(encoder, decoder)\n",
        "print(\"sanity check\", seq2seq(src, tgt[:, 1:3])[0].shape)"
      ],
      "metadata": {
        "id": "MXom1L1p0qbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(train_dataloader, val_dataloader, seq2seq)"
      ],
      "metadata": {
        "id": "HLyvWBf7ysur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valloss = 0\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "seq2seq.to(device)\n",
        "seq2seq.train()\n",
        "\n",
        "for src, tgt in train_dataloader:\n",
        "  src, tgt = src.to(device), tgt.to(device)\n",
        "  decoder_input, decoder_output = deepcopy(tgt[:, :-1]), deepcopy(tgt[:, 1:])\n",
        "  pred = seq2seq(src, decoder_input)[0]\n",
        "  loss = MaskedNLL(pred.reshape(-1, pred.shape[-1]), decoder_output.reshape(-1))\n",
        "  valloss += loss.item()"
      ],
      "metadata": {
        "id": "ZOqq2GieRToO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "with torch.no_grad():\n",
        "  for src, tgt in val_dataloader:\n",
        "      # start = time.time()\n",
        "      src, tgt = src.to(device), tgt.to(device)\n",
        "      decoder_input, decoder_output = deepcopy(tgt[:, :-1]), deepcopy(tgt[:, 1:])\n",
        "      pred = seq2seq(src, decoder_input)[0]\n",
        "      loss = MaskedNLL(pred.reshape(-1, pred.shape[-1]), decoder_output.reshape(-1))\n",
        "      pred_tokens = torch.argmax(pred, dim=-1)"
      ],
      "metadata": {
        "id": "m0nvJGa_XJ4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(val_loss)"
      ],
      "metadata": {
        "id": "0sSGKUPwF3Te"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq2seq.eval().cuda()\n",
        "idx = 123\n",
        "src.shape, tgt.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzRaz7UFJua7",
        "outputId": "9c926061-150b-4017-d99f-6eb09d22283e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([10]), torch.Size([10]))"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "src, tgt = dataset[1]"
      ],
      "metadata": {
        "id": "ZDHCIopTpMUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "' '.join([frVocab.idx2word[i.item()] for i in tgt]), ' '.join([engVocab.idx2word[i.item()] for i in src])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AI5312z3pSfq",
        "outputId": "e9b666c0-c248-4427-fc0a-802ed79bbc7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('[BOS] salut ! [EOS] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]',\n",
              " '[BOS] hi . [EOS] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]')"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = torch.argmax(seq2seq(src.unsqueeze(0).cuda(), tgt[:-1].unsqueeze(0).cuda())[0], dim=-1).view(-1)"
      ],
      "metadata": {
        "id": "cON9ltcoJ7Bf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "' '.join([frVocab.idx2word[i.item()] for i in output]), ' '.join([frVocab.idx2word[i.item()] for i in tgt])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6IPBpNKLhmT",
        "outputId": "50b36b61-af1d-4990-fe8b-b2d5e7db624e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('salut . [EOS] . ! ! . . !',\n",
              " '[BOS] salut ! [EOS] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]')"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pa4lJA9Z4Tbe"
      },
      "source": [
        "#DRIVE mnt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kV9-S054V4r",
        "outputId": "7029d4a1-c63d-4eef-fafc-43483a983f33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wqkloD3w4bax"
      },
      "outputs": [],
      "source": [
        "!cp /content/drive/MyDrive/text_eng_fr.csv /content"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r data_eng_fr.zip /content/text_eng_fr.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URO8WHKAqCzr",
        "outputId": "5a6480e9-35a7-4f4c-c458-b7930ad281ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/text_eng_fr.csv (deflated 72%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#only unzip if file uploaded\n",
        "!unzip /content/data_eng_fr.zip -d /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARtJmXLXG5yr",
        "outputId": "7d1bd731-761e-4c1d-a2ad-2dbad5bbe346"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/data_eng_fr.zip\n",
            "  inflating: /content/content/text_eng_fr.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZXjJAf644Ug",
        "outputId": "ad96ceb9-064c-4347-aedb-ac61d5d7791d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "#build vocab for sample dataset\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "import numpy as np \n",
        "import re\n",
        "import nltk\n",
        "import string\n",
        "import pandas as pd\n",
        "import time \n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AXdu3LHj5D32"
      },
      "outputs": [],
      "source": [
        "#vocab prepare class\n",
        "class Vocab:\n",
        "    def __init__(self, name=None):\n",
        "        self.name = name\n",
        "        self.word2idx = {\"[PAD]\": 0, \"[BOS]\": 1, \"[EOS]\": 2}\n",
        "        self.idx2word = {0: \"[PAD]\", 1: \"[BOS]\", 2: \"[EOS]\"} #3 special keywords\n",
        "        self.num_words = 3\n",
        "        self.word_counts = {} #SOS, EOS, PAD\n",
        "    def tokenize(self, sentence):\n",
        "        tokens = []\n",
        "        for word in sentence.split():\n",
        "          tokens.append(self.word2idx[word])\n",
        "        return tokens\n",
        "\n",
        "    def add_sentence(self, sentence):\n",
        "        for word in sentence.split():\n",
        "            self.add_word(word)\n",
        "    def add_word(self, word):\n",
        "        if word in self.word2idx.keys():\n",
        "            self.word_counts[word] += 1\n",
        "        else:\n",
        "            self.word2idx[word] = self.num_words\n",
        "            self.idx2word[self.num_words] = word\n",
        "            self.word_counts[word] = 1 \n",
        "            self.num_words += 1\n",
        "\n",
        "#normalize words class \n",
        "class normalize_funcs:\n",
        "    def __init__(self, rareword=None):\n",
        "        self.punctuation = string.punctuation\n",
        "        self.rareword = rareword\n",
        "    def lower_case(self, text):\n",
        "        return text.lower()\n",
        "\n",
        "    def remove_punctuation(self, text):\n",
        "        return text.translate(str.maketrans('', '', self.punctuation))\n",
        "\n",
        "    def remove_rareword(self, text):\n",
        "        return ' '.join(word for word in text.split() if word not in self.rareword)\n",
        "    #trimming pair of source and target\n",
        "    def trimming(self, input, target, min_freq=1):\n",
        "        counter = {}\n",
        "        for arg in [input, target]:\n",
        "            for line in arg:\n",
        "                for word in line.split():\n",
        "                    if word in counter:\n",
        "                        counter[word] += 1\n",
        "                    else:\n",
        "                        counter[word] = 1\n",
        "        #min freq = 3\n",
        "        rare_words = []\n",
        "\n",
        "        \n",
        "        for key, value in counter.items():\n",
        "            if value < min_freq:\n",
        "                rare_words.append(key)\n",
        "        print(\"RARE\", len(rare_words), len(counter.keys())) \n",
        "        #trimming\n",
        "        new_input = []\n",
        "        new_target = []\n",
        "        for line1, line2 in zip(input, target):\n",
        "            # for word in rare_words:\n",
        "            #     if word in line1:\n",
        "            #         line1 = line1.replace(word, \"\")\n",
        "            #     if word in line2:\n",
        "            #         line2 = line2.replace(word, \"\")\n",
        "                    \n",
        "    \n",
        "            new_input.append(line1.strip())\n",
        "            new_target.append(line2.strip())\n",
        "        return new_input, new_target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Yw8HaPK5Zxc"
      },
      "outputs": [],
      "source": [
        "#sample data english -> france\n",
        "data = pd.read_csv(\"/content/content/text_eng_fr.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mmyrIrwv5vIi"
      },
      "outputs": [],
      "source": [
        "engVocab = Vocab(\"English\")\n",
        "frVocab = Vocab(\"French\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_XN-XOtj6Cz1"
      },
      "outputs": [],
      "source": [
        "for i in range(len(data)):\n",
        "  src, tgt = data.iloc[i][['src', 'tgt']]\n",
        "  engVocab.add_sentence(src)\n",
        "  frVocab.add_sentence(tgt)\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNc0RZ1B9tvK",
        "outputId": "e06cd9ed-e7ae-41fd-bb14-aedce3629774"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([1, 3, 4, 2], 14883, 29345)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "engVocab.tokenize(\"[BOS] go . [EOS]\"), engVocab.num_words, frVocab.num_words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIkNkzdL8Ol9"
      },
      "source": [
        "#Env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nwbQhZx6fPD",
        "outputId": "ad4aa823-8a7e-4403-eebf-142c720c932e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'deep-learning'...\n",
            "remote: Enumerating objects: 539, done.\u001b[K\n",
            "remote: Counting objects: 100% (149/149), done.\u001b[K\n",
            "remote: Compressing objects: 100% (87/87), done.\u001b[K\n",
            "remote: Total 539 (delta 77), reused 127 (delta 61), pack-reused 390\n",
            "Receiving objects: 100% (539/539), 18.45 MiB | 7.45 MiB/s, done.\n",
            "Resolving deltas: 100% (258/258), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/baochi0212/deep-learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_4W36bd7J2E",
        "outputId": "70aa76c1-fa4f-48b3-e2e8-95dbdacc7117"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/deep-learning\n"
          ]
        }
      ],
      "source": [
        "%cd deep-learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6wceyNRJ9Ot",
        "outputId": "591c0db9-1d88-4c5d-bd09-7347e77985ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n"
          ]
        }
      ],
      "source": [
        "!git pull"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZh7W_op7TO8",
        "outputId": "1df8e086-21f1-4019-cb0f-65f3a6d12dcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* \u001b[32mmaster\u001b[m\n"
          ]
        }
      ],
      "source": [
        "!git branch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8A3gTO2s7VAM",
        "outputId": "a8ee8505-d437-4683-e117-2cf96f562294"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Branch 'NLP/feature/implement/transformer' set up to track remote branch 'NLP/feature/implement/transformer' from 'origin'.\n",
            "Switched to a new branch 'NLP/feature/implement/transformer'\n"
          ]
        }
      ],
      "source": [
        "!git checkout NLP/feature/implement/transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9JqsW367bV6",
        "outputId": "5c9ad513-af77-462f-bd91-e20aaf8d66f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/deep-learning/NLP/implement/temp\n"
          ]
        }
      ],
      "source": [
        "%cd NLP/implement/temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1wiAyzK75DZ",
        "outputId": "2dc77d71-e491-4d25-bac4-e7856f53b0d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/deep-learning/NLP/implement/temp\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QH5nQfP7k2s",
        "outputId": "ee9b4b74-6fda-4e05-f09d-f3685b8fed1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: dir=/content/deep-learning/NLP/implement/temp\n"
          ]
        }
      ],
      "source": [
        "%env dir=/content/deep-learning/NLP/implement/temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cr-OHhI8FnB",
        "outputId": "4769a251-6763-4b66-cd15-113cd18e90a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/deep-learning/NLP/implement/temp\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "print(os.environ['dir'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGYDLeGi8Sxc"
      },
      "source": [
        "#packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ctSZ7vh8JiI",
        "outputId": "8ca5cb40-04ff-47d1-bb56-2929cbccc109"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.8 MB 10.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 50.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 705 kB 69.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 151 kB 18.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 71.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 181 kB 73.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 71.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 59.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 79.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 78.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 156 kB 80.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 39.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 101 kB 12.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 419 kB 74.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 5.9 MB 50.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 117 kB 74.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 79 kB 8.9 MB/s \n",
            "\u001b[?25h  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.2+zzzcolab20220719082949 requires tensorboard<2.9,>=2.8, but you have tensorboard 2.10.0 which is incompatible.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install -q wandb transformers pytorch_lightning hydra-core einops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfZlv-3A8WRr",
        "outputId": "0c2ea1cb-d054-4ebb-fea6-a485ff19b88a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ],
      "source": [
        "!wandb login #2d91e76209897f5a66538d84313115d103f06dd9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9Y5LH46Eq6G",
        "outputId": "7542e6b1-ae85-4d54-b5b3-af571d5bebde"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/deep-learning/NLP/implement/temp/data\n"
          ]
        }
      ],
      "source": [
        "%cd /content/deep-learning/NLP/implement/temp/data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvcCzW298orV",
        "outputId": "80450950-5dae-4b31-9344-43f1ebde6a5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-08-11 14:28:10--  http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip\n",
            "Resolving www.cs.cornell.edu (www.cs.cornell.edu)... 132.236.207.36\n",
            "Connecting to www.cs.cornell.edu (www.cs.cornell.edu)|132.236.207.36|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9916637 (9.5M) [application/zip]\n",
            "Saving to: ‘cornell_movie_dialogs_corpus.zip’\n",
            "\n",
            "cornell_movie_dialo 100%[===================>]   9.46M  24.3MB/s    in 0.4s    \n",
            "\n",
            "2022-08-11 14:28:11 (24.3 MB/s) - ‘cornell_movie_dialogs_corpus.zip’ saved [9916637/9916637]\n",
            "\n",
            "Archive:  raw/cornell_movie_dialogs_corpus.zip\n",
            "   creating: cornell movie-dialogs corpus/\n",
            "  inflating: cornell movie-dialogs corpus/.DS_Store  \n",
            "   creating: __MACOSX/\n",
            "   creating: __MACOSX/cornell movie-dialogs corpus/\n",
            "  inflating: __MACOSX/cornell movie-dialogs corpus/._.DS_Store  \n",
            "  inflating: cornell movie-dialogs corpus/chameleons.pdf  \n",
            "  inflating: __MACOSX/cornell movie-dialogs corpus/._chameleons.pdf  \n",
            "  inflating: cornell movie-dialogs corpus/movie_characters_metadata.txt  \n",
            "  inflating: cornell movie-dialogs corpus/movie_conversations.txt  \n",
            "  inflating: cornell movie-dialogs corpus/movie_lines.txt  \n",
            "  inflating: cornell movie-dialogs corpus/movie_titles_metadata.txt  \n",
            "  inflating: cornell movie-dialogs corpus/raw_script_urls.txt  \n",
            "  inflating: cornell movie-dialogs corpus/README.txt  \n",
            "  inflating: __MACOSX/cornell movie-dialogs corpus/._README.txt  \n"
          ]
        }
      ],
      "source": [
        "!bash download_data.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyeo8nvqF5Ak",
        "outputId": "11a3555e-0f59-4c69-9920-f2b510633337"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "Expressing my opinion is not a terrorist action.\n",
            "\n",
            "----INPUT, TARGET Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again. Well, I thought we'd start with pronunciation, if that's okay with you.\n",
            "\n",
            "RARE 0 62429\n",
            "----data                                                    input                                    target\n",
            "0             gosh if only we could find kat a boyfriend                  let me see what i can do\n",
            "1                           cesc ma tete this is my head      right  see  youre ready for the quiz\n",
            "2                                                  there                                     where\n",
            "3                       you have my word  as a gentleman                               youre sweet\n",
            "4                                                     hi  looks like things worked out tonight huh\n",
            "...                                                  ...                                       ...\n",
            "64956                         what oclock is it mr noggs                  eleven oclock my lorj 42\n",
            "64957     are you dictating the strategy of this war sir                  im explaining my reasons\n",
            "64958                                             stuart                                       yes\n",
            "64959  well fed or hungry pulleine wants them in posi...            right  bombardier to me please\n",
            "64960   do you think she might be interested in  someone                                 which one\n",
            "\n",
            "[64961 rows x 2 columns]\n",
            "OFFICIAL DATA                                                    input                                    target\n",
            "0             gosh if only we could find kat a boyfriend                  let me see what i can do\n",
            "1                           cesc ma tete this is my head      right  see  youre ready for the quiz\n",
            "2                                                  there                                     where\n",
            "3                       you have my word  as a gentleman                               youre sweet\n",
            "4                                                     hi  looks like things worked out tonight huh\n",
            "...                                                  ...                                       ...\n",
            "64956                         what oclock is it mr noggs                  eleven oclock my lorj 42\n",
            "64957     are you dictating the strategy of this war sir                  im explaining my reasons\n",
            "64958                                             stuart                                       yes\n",
            "64959  well fed or hungry pulleine wants them in posi...            right  bombardier to me please\n",
            "64960   do you think she might be interested in  someone                                 which one\n",
            "\n",
            "[64961 rows x 2 columns]\n",
            "DF 64961\n",
            "VOCAB movie\n",
            "NUMWORDS 27008\n"
          ]
        }
      ],
      "source": [
        "!python /content/deep-learning/NLP/implement/temp/src/dataset/preprocess.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EZ5og_eGD1i",
        "outputId": "8e4cc550-f83c-4cf3-eedc-c592a7ada09b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading tokenizer_config.json: 100% 29.0/29.0 [00:00<00:00, 36.3kB/s]\n",
            "Downloading config.json: 100% 570/570 [00:00<00:00, 822kB/s]\n",
            "Downloading vocab.txt: 100% 208k/208k [00:00<00:00, 1.81MB/s]\n",
            "Downloading tokenizer.json: 100% 426k/426k [00:00<00:00, 2.95MB/s]\n",
            "Df                                                    input                                    target\n",
            "0             gosh if only we could find kat a boyfriend                  let me see what i can do\n",
            "1                           cesc ma tete this is my head      right  see  youre ready for the quiz\n",
            "2                                                  there                                     where\n",
            "3                       you have my word  as a gentleman                               youre sweet\n",
            "4                                                     hi  looks like things worked out tonight huh\n",
            "...                                                  ...                                       ...\n",
            "64956                         what oclock is it mr noggs                  eleven oclock my lorj 42\n",
            "64957     are you dictating the strategy of this war sir                  im explaining my reasons\n",
            "64958                                             stuart                                       yes\n",
            "64959  well fed or hungry pulleine wants them in posi...            right  bombardier to me please\n",
            "64960   do you think she might be interested in  someone                                 which one\n",
            "\n",
            "[64961 rows x 2 columns]\n",
            "Decode [SOS] gosh if only we could find kat a boyfriend [EOS] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/deep-learning/NLP/implement/temp/src/dataset/dataset.py\", line 64, in <module>\n",
            "  File \"/content/deep-learning/NLP/implement/temp/src/dataset/dataset.py\", line 36, in __getitem__\n",
            "    while len(tokenizer(tgt)['input_ids']) < self.max_length + 2:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py\", line 2555, in __call__\n",
            "    **kwargs,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py\", line 2628, in encode_plus\n",
            "    **kwargs,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_fast.py\", line 525, in _encode_plus\n",
            "    for key, value in batched_output.items()\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "!python /content/deep-learning/NLP/implement/temp/src/dataset/dataset.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7bStxbuKH0ke"
      },
      "outputs": [],
      "source": [
        "!python /content/deep-learning/NLP/implement/temp/src/models/main.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20hGD62_NjeA",
        "outputId": "ffe87971-60c8-4bee-ee16-783c03067cff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "bf PE tensor(0.0220, device='cuda:0')\n",
            "grad checking True False\n",
            "Attention Block tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.5080, 0.4920, 0.0000, 0.0000, 0.0000],\n",
            "        [0.3428, 0.3168, 0.3405, 0.0000, 0.0000],\n",
            "        [0.2479, 0.2485, 0.2501, 0.2535, 0.0000],\n",
            "        [0.1992, 0.1981, 0.2006, 0.2014, 0.2008]], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "af PE tensor(-0.9265, device='cuda:0')\n",
            "seq2seq torch.Size([1, 4, 10000]) cuda:0\n"
          ]
        }
      ],
      "source": [
        "!python /content/deep-learning/NLP/implement/temp/src/models/modules.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyRU81tDkx3T"
      },
      "source": [
        "#train "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "id": "Dam66c1ZOAZK",
        "outputId": "0bd2227e-44a1-4291-e557-fabede8a4085"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decode [SOS] my father banks part of his salary every week. [EOS] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-80-1c32e14968a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVOCAB_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_seq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_LEN\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_ff\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_drop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0mseq2seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSeq2Seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sanity check\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq2seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m     \u001b[0mplModule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChatMachine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'teacher_forcing'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"params\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplModule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/deep-learning/NLP/implement/temp/src/models/modules.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;31m#decoder:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/deep-learning/NLP/implement/temp/src/models/modules.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, state)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPositionalEncoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'direct'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_drop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp_drop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_attention_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mask_attention'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_attention\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_attention_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/deep-learning/NLP/implement/temp/src/models/modules.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, state)\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/deep-learning/NLP/implement/temp/src/models/modules.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, q, k, v, mask)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_v\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;31m#save the attention weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAttentionWeight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;31m#concat heads + proj to original (Same shape notwithstandingsss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/deep-learning/NLP/implement/temp/src/utils.py\u001b[0m in \u001b[0;36mAttentionWeight\u001b[0;34m(q, k, v, mask, type)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"dot\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mdot_product\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mmask_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdot_product\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_fill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#DCM NGU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected size for first two dimensions of batch2 tensor to be: [512, 64] but got: [1024, 64]."
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import random\n",
        "from copy import deepcopy\n",
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "PATH = os.environ['dir']\n",
        "sys.path.append(PATH + \"/src\")\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pytorch_lightning as pl\n",
        "import wandb\n",
        "import hydra\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, LearningRateMonitor\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "from transformers import AutoTokenizer\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "\n",
        "from dataset.dataset import ChatDataset\n",
        "from models.modules import Seq2Seq, Encoder, Decoder\n",
        "from utils import MaskedNLL\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
        "special_tokens_dict = {'additional_special_tokens': ['[SOS]','[EOS]']}\n",
        "tokenizer.add_special_tokens(special_tokens_dict)\n",
        "\n",
        "'''\n",
        "- pl_module\n",
        "- simple torch script for debug\n",
        "''' \n",
        "total_loss = []\n",
        "\n",
        "class ChatMachine(pl.LightningModule):\n",
        "    '''\n",
        "    lightning module for dataloader, training and testing\n",
        "    '''\n",
        "    def __init__(self, lr, mode='teacher_forcing'):\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder(vocab=VOCAB_SIZE, n_seq=MAX_LEN, d_model=512, d_ff=2048, h=8, N=6, p_drop=0.1, label_smoothing=None)\n",
        "        self.decoder = Decoder(vocab=VOCAB_SIZE, n_seq=MAX_LEN-1, d_model=512, d_ff=2048, h=8, N=6, p_drop=0.1, label_smoothing=None)\n",
        "        self.model = Seq2Seq(self.encoder, self.decoder)\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        src, tgt = batch\n",
        "        decoder_input, decoder_output = deepcopy(tgt[:, :-1]), deepcopy(tgt[:, 1:])\n",
        "        pred = self.model(src, decoder_input)[0]\n",
        "\n",
        "        #teacher forcing a.k.a use default ground truth (use current word -> next word) \n",
        "        if self.hparams.mode == \"teacher_forcing\":\n",
        "            loss = MaskedNLL(pred.reshape(-1, pred.shape[-1]), decoder_output.reshape(-1))\n",
        "            pred_tokens = torch.argmax(pred, dim=-1)\n",
        "            self.log(\"train loss\", loss)\n",
        "            return loss\n",
        "        #uniform random sampling, iterate through the n_seq of target\n",
        "        else:\n",
        "            pred_tokens = torch.argmax(pred, dim=-1)\n",
        "            for i in range(tgt[:, :-1].shape[1]):\n",
        "                p = random.uniform(0, 1)\n",
        "                if p > 0.69:\n",
        "                    decoder_input[:, i] = pred_tokens[:, i]\n",
        "            pred = self.model(src, decoder_input)[0]\n",
        "            loss = MaskedNLL(pred.reshape(-1, pred.shape[-1]), decoder_output.reshape(-1))\n",
        "            pred_tokens = torch.argmax(pred, dim=-1)\n",
        "            self.log(\"train loss\", loss)\n",
        "            return loss\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.hparams.lr)\n",
        "        return {'optimizer': optimizer}\n",
        "\n",
        "\n",
        "def train(train_dataloader, val_dataloader, model, mode='teacher_forcing', device = 'cuda' if torch.cuda.is_available() else 'cpu', lr=5e-6):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "    for i in range(3):\n",
        "        for src, tgt in train_dataloader:\n",
        "            optimizer.zero_grad()\n",
        "            src, tgt = src.to(device), tgt.to(device)\n",
        "            decoder_input, decoder_output = deepcopy(tgt[:, :-1]), deepcopy(tgt[:, 1:])\n",
        "            pred = model(src, decoder_input)[0]\n",
        "            if mode == \"teacher_forcing\":\n",
        "                loss = MaskedNLL(pred.reshape(-1, pred.shape[-1]), decoder_output.reshape(-1))\n",
        "                pred_tokens = torch.argmax(pred, dim=-1)\n",
        "            #uniform random sampling, iterate through the n_seq of target\n",
        "            else:\n",
        "                pred_tokens = torch.argmax(pred, dim=-1)\n",
        "                for i in range(tgt[:, :-1].shape[1]):\n",
        "                    p = random.uniform(0, 1)\n",
        "                    if p > 0.69:\n",
        "                        decoder_input[:, i] = pred_tokens[:, i]\n",
        "                pred = model(src, decoder_input)[0]\n",
        "                loss = MaskedNLL(pred.reshape(-1, pred.shape[-1]), decoder_output.reshape(-1))\n",
        "                pred_tokens = torch.argmax(pred, dim=-1)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss.append(loss.item())\n",
        "            if len(total_loss) % 50 == 0:\n",
        "                print(\"Loss: \", loss.item())\n",
        "\n",
        "\n",
        "        \n",
        "\n",
        "                    \n",
        "                \n",
        "if __name__ == \"__main__\":\n",
        "    #const\n",
        "    MAX_LEN = 20\n",
        "    VOCAB_SIZE = len(tokenizer.vocab.keys())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    #data\n",
        "    \n",
        "    # data = pd.read_csv(os.path.join(PATH, 'data/raw/cornell movie-dialogs corpus/pair_df.csv'), sep='@')\n",
        "    # print(\"Df\", data)\n",
        "    train_data, val_data = train_test_split(data, test_size=0.3)\n",
        "    train_dataset = ChatDataset(train_data, max_length=MAX_LEN)\n",
        "    val_dataset = ChatDataset(val_data, max_length=MAX_LEN)\n",
        "    src_token, tgt_token = train_dataset[0]\n",
        "    print(\"Decode\", tokenizer.decode(src_token))\n",
        "    # train_dataset, val_dataset = train_test_split(dataset, test_size=0.3)\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, drop_last=True)\n",
        "    val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=True, drop_last=True)\n",
        "    src, tgt = iter(train_dataloader).next()\n",
        "\n",
        "    # #define lightning module \n",
        "    encoder = Encoder(vocab=VOCAB_SIZE, n_seq=MAX_LEN, d_model=256, d_ff=64, h=4, N=2, p_drop=0.1, label_smoothing=None)\n",
        "    decoder = Decoder(vocab=VOCAB_SIZE, n_seq=MAX_LEN-1, d_model=256, d_ff=64, h=4, N=2, p_drop=0.1, label_smoothing=None)\n",
        "    seq2seq = Seq2Seq(encoder, decoder)\n",
        "    print(\"sanity check\", seq2seq(src, tgt[:, 1:3])[0].shape)\n",
        "    plModule = ChatMachine(lr=0.01, mode='teacher_forcing')\n",
        "    print(\"params\", plModule.hparams.mode)\n",
        "    pred, state = seq2seq(src, tgt[:, :-1])\n",
        "    print(\"Loss\", MaskedNLL(pred.reshape(-1, pred.shape[-1]), tgt[:, 1:].reshape(-1)))\n",
        "    print(len(state[2]))\n",
        "    # #set up\n",
        "    # wandb_logger = WandbLogger(project='lightning_tutorial', save_dir=os.path.join(PATH, 'src/runtime'))\n",
        "    # ckp_dir = os.path.join(PATH, \"src/runtime/checkpoints\")\n",
        "    # custom_callbacks = [LearningRateMonitor(logging_interval='step'), EarlyStopping(monitor='val loss: ', mode='min', patience=3), ModelCheckpoint(dirpath='/media/data/chitb/study_zone/ML-_midterm_20212/final_ckp', monitor='val loss: ', mode='min')]\n",
        "    # #training \n",
        "    # trainer = pl.Trainer(accelerator='cuda' if torch.cuda.is_available() else 'cpu',  default_root_dir=ckp_dir, logger=wandb_logger, callbacks=custom_callbacks, max_epochs=3, fast_dev_run=True)\n",
        "    # trainer.fit(plModule, dataloader)\n",
        "    # train(train_dataloader, val_dataloader, seq2seq)\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "hK9UA1GnyIhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XW8yfhSee1uA"
      },
      "outputs": [],
      "source": [
        "def MaskedNLL(pred, label):\n",
        "    mask = label == 0\n",
        "    loss = nn.CrossEntropyLoss(reduction='none')(pred, label)\n",
        "    loss = loss.masked_fill(mask, 0)\n",
        "    print(\"Loss\", loss)\n",
        "    return loss.mean(dim=-1)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEo4_CSDOb78"
      },
      "outputs": [],
      "source": [
        "a = torch.rand(5, 6)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tomL4UvtfMpu"
      },
      "outputs": [],
      "source": [
        " b = torch.tensor([1,2,3,4,0], dtype=torch.long).reshape(-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PiNqVFYPfRve",
        "outputId": "d737e8ad-8832-4d80-db19-de0d17e796ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss tensor([2.2161, 1.9918, 1.9055, 2.3872, 0.0000])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor(1.7001)"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "MaskedNLL(a, b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "8Nsei8xiRe_3",
        "outputId": "42fe08e5-efd8-4ca0-f44f-1021c33d420e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f5cc0921e90>]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(total_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "boG4wNJqvU0C"
      },
      "outputs": [],
      "source": [
        "# device='cuda' if torch.cuda.is_available() else 'cpu'\n",
        "# seq2seq.to(device)\n",
        "# seq2seq.eval()\n",
        "# src = \"I am happy\"\n",
        "# src = \"[SOS] \" + src + \" [EOS]\" \n",
        "# while len(tokenizer(src)['input_ids']) < MAX_LEN:\n",
        "#   src += \" [PAD]\"\n",
        "# src_token = tokenizer(src)['input_ids']\n",
        "# if len(src_token) < MAX_LEN:\n",
        "#   src_token = src_token[:MAX_LEN]\n",
        "# print(\"len\", len(src_token))\n",
        "# #decode\n",
        "# src_token = torch.tensor(src_token, dtype=torch.long).reshape(1, -1).to(device)\n",
        "device='cuda'\n",
        "src_token, tgt_token = next(iter(train_dataloader))\n",
        "src_token, decoder_input = src_token.to(device), tgt_token[:, :-1].to(device)\n",
        "encode_input = seq2seq.encoder(src_token)\n",
        "state = seq2seq.decoder.init_state(encode_input, encode_input.shape[1])\n",
        "# tgt = '[SOS] + me too'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMYdnvnVv06_",
        "outputId": "d19c8152-8cd6-4e31-920f-26363e4fa236"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([16, 14])\n",
            "tensor([17,  2, 17, 17, 17,  2, 17, 17, 17,  2,  2, 17,  2, 17],\n",
            "       device='cuda:0')\n",
            "['.', '[EOS]', '.', '.', '.', '[EOS]', '.', '.', '.', '[EOS]', '[EOS]', '.', '[EOS]', '.']\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(decoder_input.shape)\n",
        "pred, state = seq2seq.decoder(decoder_input, state)\n",
        "pred = torch.argmax(pred, dim =-1)\n",
        "print(pred[0]), print([frVocab.idx2word[idx.item()] for idx in pred[0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIlaV0wUHhj1",
        "outputId": "ebf183d7-93ac-4540-d17a-71cc3b354542"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['[BOS]', 'ma', 'femme', 'est', 'bon', 'imprésario', '.', '[EOS]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n"
          ]
        }
      ],
      "source": [
        "print([frVocab.idx2word[idx.item()] for idx in decoder_input[0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtP-VdrGO2hB",
        "outputId": "54cc9ca2-8479-46d5-8b86-65d415c43e43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "len 20\n",
            "torch.Size([1, 1])\n",
            "pred 28997\n",
            "[SOS] [EOS]\n",
            "torch.Size([1, 2])\n",
            "pred 28997\n",
            "[SOS] [EOS] [EOS]\n",
            "torch.Size([1, 3])\n",
            "pred 28997\n",
            "[SOS] [EOS] [EOS] [EOS]\n",
            "torch.Size([1, 4])\n",
            "pred 28997\n",
            "[SOS] [EOS] [EOS] [EOS] [EOS]\n",
            "torch.Size([1, 5])\n",
            "pred 28997\n",
            "[SOS] [EOS] [EOS] [EOS] [EOS] [EOS]\n",
            "torch.Size([1, 6])\n",
            "pred 28997\n",
            "[SOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS]\n",
            "torch.Size([1, 7])\n",
            "pred 28997\n",
            "[SOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS]\n",
            "torch.Size([1, 8])\n",
            "pred 28997\n",
            "[SOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS]\n",
            "torch.Size([1, 9])\n",
            "pred 28997\n",
            "[SOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS]\n",
            "torch.Size([1, 10])\n",
            "pred 28997\n",
            "[SOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS]\n",
            "torch.Size([1, 11])\n",
            "pred 28997\n",
            "[SOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS]\n",
            "torch.Size([1, 12])\n",
            "pred 28997\n",
            "[SOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS]\n",
            "torch.Size([1, 13])\n",
            "pred 28997\n",
            "[SOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS]\n",
            "torch.Size([1, 14])\n",
            "pred 28997\n",
            "[SOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS]\n",
            "torch.Size([1, 15])\n",
            "pred 28997\n",
            "[SOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS]\n",
            "torch.Size([1, 16])\n",
            "pred 28997\n",
            "[SOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS]\n",
            "torch.Size([1, 17])\n",
            "pred 28997\n",
            "[SOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS]\n",
            "torch.Size([1, 18])\n",
            "pred 28997\n",
            "[SOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS]\n",
            "torch.Size([1, 19])\n",
            "pred 28997\n",
            "[SOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS]\n",
            "torch.Size([1, 20])\n",
            "pred 28997\n",
            "[SOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS] [EOS]\n"
          ]
        }
      ],
      "source": [
        "def inference(model, src, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
        "  model.to(device)\n",
        "  model.eval()\n",
        "  src = \"[SOS] \" + src + \" [EOS]\" \n",
        "  while len(tokenizer(src)['input_ids']) < MAX_LEN:\n",
        "    src += \" [PAD]\"\n",
        "  src_token = tokenizer(src)['input_ids']\n",
        "  if len(src_token) < MAX_LEN:\n",
        "    src_token = src_token[:MAX_LEN]\n",
        "  print(\"len\", len(src_token))\n",
        "  #decode\n",
        "  src_token = torch.tensor(src_token, dtype=torch.long).reshape(1, -1).to(device)\n",
        "  encode_input = model.encoder(src_token)\n",
        "  state = model.decoder.init_state(encode_input, encode_input.shape[1])\n",
        "  tgt = '[SOS]'\n",
        "  for i in range(MAX_LEN):\n",
        "    decoder_input = torch.tensor(tokenizer(tgt)['input_ids'], dtype=torch.long)[1:-1].reshape(1, -1).to(device)\n",
        "    print(decoder_input.shape)\n",
        "    pred, state = model.decoder(decoder_input, state)\n",
        "    pred = torch.argmax(pred[-1], dim =-1)\n",
        "    print(\"pred\", pred[-1].item())\n",
        "    tgt += \" \" + tokenizer.decode(pred[-1], dim =-1) \n",
        "    print(tgt)\n",
        "    \n",
        "inference(seq2seq, \"today is good\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "XVZWefOre0-d",
        "outputId": "d32df59b-5622-4f83-931e-07e2b6e006c8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'##nton'"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.convert_ids_to_tokens(13124)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PSDR3I1rhmjf"
      },
      "outputs": [],
      "source": [
        "a = torch.tensor(3).cuda()\n",
        "b = torch.tensor(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "id": "CJIzI-adhot6",
        "outputId": "2736ff60-deaa-466d-9da4-735fe65d8dcc"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-56659b506e2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_fill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: expected self and mask to be on the same device, but got mask on cpu and self on cuda:0"
          ]
        }
      ],
      "source": [
        "a.masked_fill(b > 0, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "za67PZUDhsRc"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "VIkNkzdL8Ol9"
      ],
      "name": "experiments_August.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}