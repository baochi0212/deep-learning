{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/baochi0212/deep-learning-/blob/master/running_chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/baochi0212/deep-learning-"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVOeltsG2zYp",
        "outputId": "a93e1b9d-9ef1-4040-a8cc-95bb26c5d000"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'deep-learning-'...\n",
            "remote: Enumerating objects: 28, done.\u001b[K\n",
            "remote: Counting objects: 100% (28/28), done.\u001b[K\n",
            "remote: Compressing objects: 100% (22/22), done.\u001b[K\n",
            "remote: Total 28 (delta 9), reused 24 (delta 5), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (28/28), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash /content/deep-learning-/download_data.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Yw2jOrrVuKP",
        "outputId": "d57784ae-e267-4dd1-864d-ea06f95c8b92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-02 15:39:48--  http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip\n",
            "Resolving www.cs.cornell.edu (www.cs.cornell.edu)... 132.236.207.36\n",
            "Connecting to www.cs.cornell.edu (www.cs.cornell.edu)|132.236.207.36|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9916637 (9.5M) [application/zip]\n",
            "Saving to: ‘cornell_movie_dialogs_corpus.zip’\n",
            "\n",
            "cornell_movie_dialo 100%[===================>]   9.46M  5.02MB/s    in 1.9s    \n",
            "\n",
            "2022-03-02 15:39:50 (5.02 MB/s) - ‘cornell_movie_dialogs_corpus.zip’ saved [9916637/9916637]\n",
            "\n",
            "Archive:  cornell_movie_dialogs_corpus.zip\n",
            "   creating: cornell movie-dialogs corpus/\n",
            "  inflating: cornell movie-dialogs corpus/.DS_Store  \n",
            "   creating: __MACOSX/\n",
            "   creating: __MACOSX/cornell movie-dialogs corpus/\n",
            "  inflating: __MACOSX/cornell movie-dialogs corpus/._.DS_Store  \n",
            "  inflating: cornell movie-dialogs corpus/chameleons.pdf  \n",
            "  inflating: __MACOSX/cornell movie-dialogs corpus/._chameleons.pdf  \n",
            "  inflating: cornell movie-dialogs corpus/movie_characters_metadata.txt  \n",
            "  inflating: cornell movie-dialogs corpus/movie_conversations.txt  \n",
            "  inflating: cornell movie-dialogs corpus/movie_lines.txt  \n",
            "  inflating: cornell movie-dialogs corpus/movie_titles_metadata.txt  \n",
            "  inflating: cornell movie-dialogs corpus/raw_script_urls.txt  \n",
            "  inflating: cornell movie-dialogs corpus/README.txt  \n",
            "  inflating: __MACOSX/cornell movie-dialogs corpus/._README.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv '/content/data' '/content/deep-learning-'"
      ],
      "metadata": {
        "id": "rucXQXYU5hqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/deep-learning-/main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LR93pCTT21yd",
        "outputId": "826e93de-4941-49c6-c922-d14acd0d5083"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/deep-learning-/main\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install einops"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eA5yRQYO27ha",
        "outputId": "9875b412-4095-4d3c-b669-b0736c29c96f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting einops\n",
            "  Downloading einops-0.4.0-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: einops\n",
            "Successfully installed einops-0.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/deep-learning-/preprocessing/preprocess.py"
      ],
      "metadata": {
        "id": "JURwF9lK33zU",
        "outputId": "2689070c-5330-4f29-d695-3e99df7f780b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "Expressing my opinion is not a terrorist action.\n",
            "\n",
            "----INPUT, TARGET Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again. Well, I thought we'd start with pronunciation, if that's okay with you.\n",
            "----data                                                    input                                    target\n",
            "0             gosh if only we could find kat a boyfriend                  let me see what i can do\n",
            "1                           cesc ma tete this is my head      right  see  youre ready for the quiz\n",
            "2                                                  there                                     where\n",
            "3                       you have my word  as a gentleman                               youre sweet\n",
            "4                                                     hi  looks like things worked out tonight huh\n",
            "...                                                  ...                                       ...\n",
            "64661                         what oclock is it mr noggs                  eleven oclock my lorj 42\n",
            "64662     are you dictating the strategy of this war sir                  im explaining my reasons\n",
            "64663                                             stuart                                       yes\n",
            "64664  well fed or hungry pulleine wants them in posi...            right  bombardier to me please\n",
            "64665   do you think she might be interested in  someone                                 which one\n",
            "\n",
            "[64666 rows x 2 columns]\n",
            "OFFICIAL DATA                                                    input                                    target\n",
            "0             gosh if only we could find kat a boyfriend                  let me see what i can do\n",
            "1                           cesc ma tete this is my head      right  see  youre ready for the quiz\n",
            "2                                                  there                                     where\n",
            "3                       you have my word  as a gentleman                               youre sweet\n",
            "4                                                     hi  looks like things worked out tonight huh\n",
            "...                                                  ...                                       ...\n",
            "64661                         what oclock is it mr noggs                  eleven oclock my lorj 42\n",
            "64662     are you dictating the strategy of this war sir                  im explaining my reasons\n",
            "64663                                             stuart                                       yes\n",
            "64664  well fed or hungry pulleine wants them in posi...            right  bombardier to me please\n",
            "64665   do you think she might be interested in  someone                                 which one\n",
            "\n",
            "[64666 rows x 2 columns]\n",
            "VOCAB movie\n",
            "NUMWORDS 26943\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bGRJSCOr2L8X",
        "outputId": "799347e2-9c6c-48e2-81d2-0b3fcd86a0de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn \n",
        "import sys\n",
        "import os \n",
        "from pathlib import Path \n",
        "from dataset import Translate_dataset\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import pandas as pd\n",
        "import torch.nn.functional as F\n",
        "from einops import repeat\n",
        "from neural_net import EncoderRNN, Attn, LuongAttnDecoderRNN\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MY VOCAB\n"
      ],
      "metadata": {
        "id": "ocUiKRnyY_wQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mg-I-j4F2L8d",
        "outputId": "74e01d02-d6c9-4679-bc3f-3e95ab0c2af0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                   input                                    target\n",
            "0             gosh if only we could find kat a boyfriend                  let me see what i can do\n",
            "1                           cesc ma tete this is my head      right  see  youre ready for the quiz\n",
            "2                                                  there                                     where\n",
            "3                       you have my word  as a gentleman                               youre sweet\n",
            "4                                                     hi  looks like things worked out tonight huh\n",
            "...                                                  ...                                       ...\n",
            "64661                         what oclock is it mr noggs                  eleven oclock my lorj 42\n",
            "64662     are you dictating the strategy of this war sir                  im explaining my reasons\n",
            "64663                                             stuart                                       yes\n",
            "64664  well fed or hungry pulleine wants them in posi...            right  bombardier to me please\n",
            "64665   do you think she might be interested in  someone                                 which one\n",
            "\n",
            "[64666 rows x 2 columns]\n",
            "VOCAB None\n",
            "NUMWORDS 26943\n"
          ]
        }
      ],
      "source": [
        "class Vocab:\n",
        "    def __init__(self, name=None):\n",
        "        self.name = name\n",
        "        self.word2idx = {\"PAD\": 0, \"SOS\": 1, \"EOS\": 2}\n",
        "        self.idx2word = {1: \"SOS\", 0: \"PAD\", 2: \"EOS\"} #3 special keywords\n",
        "        self.num_words = 3\n",
        "        self.word_counts = {} #SOS, EOS, PAD\n",
        "\n",
        "    def add_sentence(self, sentence):\n",
        "        for word in sentence.split():\n",
        "            self.add_word(word)\n",
        "    def add_word(self, word):\n",
        "        if word in self.word2idx.keys():\n",
        "            self.word_counts[word] += 1\n",
        "\n",
        "        else:\n",
        "            self.word2idx[word] = self.num_words\n",
        "            self.idx2word[self.num_words] = word\n",
        "            self.word_counts[word] = 1 \n",
        "            self.num_words += 1\n",
        "\n",
        "class normalize_funcs:\n",
        "    def __init__(self, rareword=None):\n",
        "        self.punctuation = string.punctuation\n",
        "        self.rareword = rareword\n",
        "    def lower_case(self, text):\n",
        "        return text.lower()\n",
        "\n",
        "    def remove_punctuation(self, text):\n",
        "        return text.translate(str.maketrans('', '', self.punctuation))\n",
        "\n",
        "    def remove_rareword(self, text):\n",
        "        return ' '.join(word for word in text.split() if word not in self.rareword)\n",
        "    def trimming(self, input, target, min_freq=3):\n",
        "        counter = {}\n",
        "        for arg in [input, target]:\n",
        "            for line in arg:\n",
        "                for word in line.split():\n",
        "                    if word in counter:\n",
        "                        counter[word] += 1\n",
        "                    else:\n",
        "                        counter[word] = 1\n",
        "\n",
        "        #min freq = 3\n",
        "\n",
        "        rare_words = []\n",
        "        for key, value in counter.items():\n",
        "            if value < min_freq:\n",
        "                rare_words.append(key)\n",
        "        #trimming\n",
        "        new_input = []\n",
        "        new_target = []\n",
        "        for line1, line2 in zip(input, target):\n",
        "            if word in line1 or word in line2:\n",
        "                continue\n",
        "            else:\n",
        "                new_input.append(line1)\n",
        "                new_target.append(line2)\n",
        "        return new_input, new_target\n",
        "\n",
        "vocab = Vocab()\n",
        "data = pd.read_csv(os.path.join('/content/deep-learning-/data/cornell movie-dialogs corpus/pair_df.csv'), sep='@')\n",
        "print(data)\n",
        "for i in range(len(data)):\n",
        "    input, target = data.iloc[i, :]\n",
        "    for line in [input, target]:\n",
        "        vocab.add_sentence(line)\n",
        "print('VOCAB', vocab.name)\n",
        "print('NUMWORDS', vocab.num_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gsIbjAkW2L8g"
      },
      "outputs": [],
      "source": [
        "def maskNLLLoss(inp, target, mask):\n",
        "    nTotal = mask.sum()\n",
        "    crossEntropy = -torch.log(torch.gather(inp, 1, target.view(-1, 1)).squeeze(1))\n",
        "    loss = crossEntropy.masked_select(mask).mean()\n",
        "    loss = loss\n",
        "    return loss, nTotal.item()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSAzqfhm2L8i"
      },
      "source": [
        "training 2\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader= DataLoader(dataset, batch_size=64, collate_fn=pad_fn)\n",
        "iter(dataloader).next()"
      ],
      "metadata": {
        "id": "Jwa0kEPyQeEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_fn(batch):\n",
        "  sample_input, sample_target, length = zip(*batch)\n",
        "  sample_input = list(sample_input)\n",
        "  sample_target = list(sample_target)\n",
        "  max_input_len = max([input.shape[0] for input in sample_input])\n",
        "  max_target_len = max([target.shape[0] for target in sample_target])\n",
        "  mask = torch.zeros([len(sample_input), sample_input[0].shape[0]])\n",
        "  for i in range(len(sample_input)):\n",
        "    if sample_input[i].shape[0] < max_input_len: \n",
        "      sample_input[i] = torch.cat([sample_input[i], torch.zeros([max_input_len - sample_input[i].shape[0]], dtype=torch.long)])\n",
        "      mask = torch.tensor([True if i.item() != 0 else False for i in sample_input[i]])\n",
        "  for i in range(len(sample_target)):\n",
        "    if sample_target[i].shape[0] < max_target_len: \n",
        "      sample_target[i] = torch.cat([sample_target[i], torch.zeros([max_target_len - sample_target[i].shape[0]], dtype=torch.long)])\n",
        " \n",
        "  return sample_input, sample_target, length, mask, max_target_len"
      ],
      "metadata": {
        "id": "lnyEh5x7OItv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TRAIN\n"
      ],
      "metadata": {
        "id": "1ga2cKziqPR1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0RJ_ryfG2L8m"
      },
      "outputs": [],
      "source": [
        "def train(input_variable, lengths, target_variable, mask, max_target_len, encoder, decoder,\n",
        "          encoder_optimizer, decoder_optimizer, batch_size, clip, device='gpu'):\n",
        "\n",
        "      #input and optimizer\n",
        "      if torch.cuda.is_available():\n",
        "        input_variable, target_variable = input_variable.cuda(), target_variable.cuda()\n",
        "        encoder.cuda()\n",
        "        decoder.cuda()\n",
        "        mask = mask.cuda()\n",
        "        decoder_input = torch.tensor([[1] for i in range(batch_size)], dtype=torch.long).reshape(1, -1).cuda()\n",
        "      else:\n",
        "        decoder_input = torch.tensor([[1] for i in range(batch_size)], dtype=torch.long).reshape(1, -1)\n",
        "      encoder_optimizer.zero_grad()\n",
        "      decoder_optimizer.zero_grad() \n",
        "\n",
        "      #feed to model\n",
        "      #encoder:\n",
        "      encoder_output, encoder_hidden = encoder(input_variable, lengths)\n",
        "      # #repeat the final hidden according to the num_layers of encoder \n",
        "      # decoder_hidden = repeat(encoder_hidden[-1], 'b h -> n b h', n=decoder.n_layers)\n",
        "      decoder_hidden = encoder_hidden[-decoder.n_layers:]\n",
        "      total_loss = 0\n",
        "      n_total = 0\n",
        "      #target shape 11 x 32 (seq x batch)\n",
        "      teacher_forcing = True\n",
        "      for i in range(max_target_len): \n",
        "          decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_output)\n",
        "          if teacher_forcing:\n",
        "            decoder_input = target_variable[i].reshape(1, batch_size) #target seq x batch\n",
        "          else:\n",
        "            decoder_input = torch.argmax(decoder_output, dim=1).reshape(1, batch_size) # seq 1 x batch 32 \n",
        "  \n",
        "          loss, ntotal = maskNLLLoss(decoder_output, target_variable[i].reshape(batch_size, 1), mask[i])\n",
        "          total_loss += loss\n",
        "          n_total += ntotal\n",
        "      \n",
        "      #backward\n",
        "      total_loss.backward()\n",
        "\n",
        "      _ = nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
        "      _ = nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
        "\n",
        "      #step\n",
        "      encoder_optimizer.step()\n",
        "      decoder_optimizer.step()\n",
        "\n",
        "      return total_loss/n_total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OufzHEn22L8q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50fefd19-6703-4b16-d223-b79f92f99b19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building encoder and decoder ...\n",
            "Models built and ready to go!\n"
          ]
        }
      ],
      "source": [
        "# Configure models\n",
        "model_name = 'cb_model'\n",
        "attn_model = 'dot'\n",
        "#attn_model = 'general'\n",
        "#attn_model = 'concat'\n",
        "hidden_size = 500\n",
        "encoder_n_layers = 2\n",
        "decoder_n_layers = 2\n",
        "dropout = 0.1\n",
        "batch_size = 64\n",
        "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "clip = 50.0\n",
        "teacher_forcing_ratio = 1.0\n",
        "learning_rate = 0.0001\n",
        "decoder_learning_ratio = 5.0\n",
        "\n",
        "\n",
        "print('Building encoder and decoder ...')\n",
        "# Initialize word embeddings\n",
        "embedding = nn.Embedding(vocab.num_words, hidden_size)\n",
        "\n",
        "# Initialize encoder & decoder models\n",
        "encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n",
        "decoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, vocab.num_words, decoder_n_layers, dropout)\n",
        "# Use appropriate device\n",
        "encoder = encoder.to(device)\n",
        "decoder = decoder.to(device)\n",
        "encoder.train()\n",
        "decoder.train()\n",
        "encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=learning_rate*decoder_learning_ratio)\n",
        "print('Models built and ready to go!')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "# XL BATCH\n"
      ],
      "metadata": {
        "id": "oBzWnBWl0f23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Translate_dataset(Dataset):\n",
        "    def __init__(self, vocab, data, MAX_LEN=10):\n",
        "        super().__init__()\n",
        "        self.vocab = vocab\n",
        "        self.data = data\n",
        "        self.MAX_LEN = MAX_LEN \n",
        "    def __getitem__(self, idx):\n",
        "        input, target = self.data.iloc[idx, :]\n",
        "        #get the tensor word:\n",
        "        tensor_input = torch.tensor([self.vocab.word2idx[word] for word in input.split()] + [self.vocab.word2idx['EOS']], dtype=torch.long)\n",
        "        tensor_target = torch.tensor([self.vocab.word2idx[word] for word in target.split()] + [self.vocab.word2idx['EOS']], dtype=torch.long)\n",
        "        item = [tensor_input, tensor_target] #just a copy not affect 2 above variables \n",
        "        #padding\n",
        "        if len(input.split()) < self.MAX_LEN + 1:\n",
        "            tensor_input = torch.cat([tensor_input, torch.zeros(self.MAX_LEN - len(input.split()), dtype=torch.long)])\n",
        "        if len(target.split()) < self.MAX_LEN + 1:\n",
        "            tensor_target = torch.cat([tensor_target, torch.zeros(self.MAX_LEN - len(target.split()), dtype=torch.long)])\n",
        "            mask = torch.tensor([True if i.item() != 0 else False for i in tensor_target])\n",
        "\n",
        "        return tensor_input.reshape(-1, 1), tensor_target.reshape(-1, 1), tensor_input.shape[0], mask.reshape(-1, 1)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "metadata": {
        "id": "5OK224LL472t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " set = Translate_dataset(vocab, data)\n",
        " print('---SHAPE', set[0][0].shape)\n",
        " #loader \n",
        " dataloader = DataLoader(set, batch_size, shuffle=True, drop_last=True)"
      ],
      "metadata": {
        "id": "YZLzhCHj46-Q",
        "outputId": "a4e972f0-114b-441d-ef28-34e16fd08203",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---SHAPE torch.Size([11, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = []\n",
        "for j in tqdm(range(10)):\n",
        "  for i, batch in enumerate(dataloader):\n",
        "      sample_input, sample_target, lengths, mask = batch\n",
        "      \n",
        "      sample_input = sample_input.squeeze(-1).permute(1, 0)\n",
        "      sample_target = sample_target.squeeze(-1).permute(1, 0)\n",
        "      mask = mask.squeeze(-1).permute(1, 0)\n",
        "      loss.append(train(sample_input, lengths, sample_target, mask, 11, encoder, decoder, encoder_optimizer, decoder_optimizer, batch_size, clip=clip))"
      ],
      "metadata": {
        "id": "Ps9-Mzx-y-nh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JtxLbOSz2L8u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "715b987f-fd60-47dc-82e7-09b2e81e615c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fe305a08a10>]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "for i in range(len(loss)):\n",
        "  loss[i] = loss[i].detach().item()\n",
        "plt.plot(loss)\n",
        "# loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4FnK44lz2L8v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22042efa-c6e9-41ba-d97b-03ac94df9bf7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LuongAttnDecoderRNN(\n",
              "  (embedding): Embedding(26943, 500)\n",
              "  (embedding_dropout): Dropout(p=0.1, inplace=False)\n",
              "  (gru): GRU(500, 500, num_layers=2, dropout=0.1)\n",
              "  (concat): Linear(in_features=1000, out_features=500, bias=True)\n",
              "  (out): Linear(in_features=500, out_features=26943, bias=True)\n",
              "  (attn): Attn()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "def evaluate(encoder, decoder, input_variable, lengths, max_length=11, device='cpu'):\n",
        "    decoder_input = torch.tensor([1], dtype=torch.long).reshape(1, 1)\n",
        "    encoder_output, encoder_hidden = encoder(input_variable, lengths)\n",
        "    # decoder_hidden = repeat(encoder_hidden[-1], 'b h -> n b h', n=decoder.n_layers)\n",
        "    decoder_hidden = encoder_hidden[-decoder.n_layers:]\n",
        "    print(encoder_output.shape, decoder_hidden.shape)\n",
        "\n",
        "    out_token = []\n",
        "    for i in range(max_length):\n",
        "        decoder_ouput, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_output)\n",
        "        out_token.append(torch.argmax(decoder_ouput, dim=1))\n",
        "        decoder_input = torch.argmax(decoder_ouput, dim=1).reshape(1, 1)\n",
        "           \n",
        "       \n",
        "       \n",
        "\n",
        "    \n",
        "    return out_token\n",
        "\n",
        "encoder.eval().cpu()\n",
        "decoder.eval().cpu()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vSvP_V_s2L8w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "c91206eb-b460-42f2-8688-2f6ba250b482"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 1, 500]) torch.Size([2, 1, 500])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'im not sure EOS EOS EOS EOS EOS EOS EOS EOS '"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "word = 'can we fuck together'\n",
        "\n",
        "\n",
        "word_tensor = torch.tensor([vocab.word2idx[i] for i in word.split()] +  [2],dtype=torch.long)\n",
        "# if len(word.split()) < 11:\n",
        "#           word_tensor = torch.cat([word_tensor, torch.zeros(10 - len(word.split()), dtype=torch.long)])\n",
        "word_tensor = word_tensor.reshape(-1, 1)\n",
        "out_token = evaluate(encoder, decoder, word_tensor, torch.tensor([len(word.split()) + 1]))\n",
        "sentence = ''\n",
        "for i in out_token:\n",
        "    sentence += vocab.idx2word[i.item()] + ' '\n",
        "sentence"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "73fdcbcaa6b22d852c0f9bd9783ab6b1b1c25c52a0a8da76beae07513436cb85"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('deeplearning')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "chatbot.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}